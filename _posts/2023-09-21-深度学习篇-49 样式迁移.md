---
published: false
layout: post
title: "预告"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "预告"
---


样式迁移（Style Transfer）



计算机视觉的应用之一，将样式图片中的样式（比如油画风格等）迁移到内容图片（比如实拍的图片）上，得到合成图片
可以理解成为一个滤镜，但相对于滤镜来讲具有更大的灵活性，一个滤镜通常只能够改变图片的某个方面，如果要达到理想中的风格，可能需要尝试大量不同的组合，这个过程的复杂程度不亚于模型调参


基于 CNN 的样式迁移



奠基性工作
使用神经网络修改内容图片，使其在样式上接近风格图片

上图中的内容图像为西雅图郊区的雷尼尔山国家公园风景照，样式图像为主题为秋天橡树的油画，最终输出的合成图像应用了样式图像的油画笔触让整体颜色更加鲜艳，同时保留了内容图像中物体主体的形状








工作原理




1、首先初始化合成图片（例如将其初始化为内容图片）

输入中有一张内容图片（Content Image）和一张样式图片（Style Image）
模型所要训练的不是卷积神经网络的权重，而是合成图片，它是样式迁移过程中唯一需要更新的变量，即样式迁移所需迭代的参数模型
2、然后选择一个预训练的卷积神经网络来抽取图片的特征（该卷积神经网络的模型参数在训练中不用更新）

内容图片、样式图片之后和合成图片（Synthesised Image）之前各有一个卷积神经网络，上图中只画了三层，看起来有三个三层的卷积神经网络，实际上三个卷积神经网络都是一样的（它们的权重是一样的）
3、这个深度神经网络凭借多个层逐级抽取图像的特征，因此可以选择其中某些层的输出作为内容特征或者样式特征（上图中的卷积神经网络第二层输出内容特征，第一层和第三层输出样式特征）

对于一张输入图片来讲，每一层的卷积神经网络都会有一个输出（特征），整个基于 CNN 的样式迁移的目的是训练出一张合成图片，使得合成图片和内容图片放进同样一个卷积神经网络的时候，合成图片在某一层的输出能够匹配上内容图片在某一层的损失（内容损失，Content Loss），即它们在内容上是相近的；同理，合成图片和内容图片所使用的是同一个卷积神经网络，在某些层的输出（特征）在样式上能够匹配的上。如果训练出一张合成图片同时满足以上需求的话，就可以认为它既保留了内容图片的内容，又保留了样式图片的样式
一般来说，越靠近输入层，越容易抽取图片的细节信息；反之，越容易抽取图片的全局信息
为了避免合成图片过多地保留内容图片的细节，选择靠近输出的层（即内容层）来输出图片的内容特征
选择不同层的输出（即风格层）来匹配局部和全局的样式
在使用卷积神经网络抽取特征时，只需要用到从输入层到最靠近输出层的内容层或者样式层之间的所有层
因为在训练的时候无需改变预训练的卷积神经网络的模型参数，所以可以在训练开始之前就提取出内容特征和风格特征
4、通过前向传播（实线箭头方向）计算样式迁移的损失函数，并通过反向传播（虚线箭头方向）迭代模型参数，即不断更新合成图片

样式迁移常用的损失函数由三部分组成：（1）内容损失通过平方误差函数衡量合成图片与内容图片在内容特征上的差异，使合成图片与内容图片在内容特征上接近；（2）样式损失也是通过平方误差函数衡量合成图片与样式图片在样式特征上的差异，使合成图片与样式图片在样式特征上接近；（3）全变分损失有助于减少合成图片中的噪点，有时学到的合成图像中有大量高频噪点（即有特别亮或者特别暗的颗粒像素），常用全变分去噪（Total Variation Denoising），通过降低全变分损失，能够尽可能使临近的像素值相似，来进行去噪
样式迁移的损失函数是内容损失、样式损失和总变化损失的加权和，通过调节这些权重超参数，可以权衡合成图片在保留内容、样式迁移以及去噪三方面的相对重要性
对于给定的输入，如果简单地调用前向传播函数，只能获得最后一层的输出，因为还需要中间层的输出，所以需要进行逐层计算，保留内容层和风格层的输出
在样式迁移中，合成图片是训练期间唯一需要更新的变量，因此可以将合成图片视为模型参数，模型的前向传播只需要返回模型参数即可
5、最后当模型训练结束时，输出样式迁移的模型参数即为最终的合成图片

因为合成图片是样式迁移所需迭代的模型参数，所以只能在训练的过程中抽取合成图片的内容特征和样式特征
合成图片保留了内容图片的内容，并同时迁移了样式图片的样式








总结



1、样式迁移常用的损失函数由 3 部分组成：内容损失、样式损失和全变分损失

内容损失使合成图片与内容图片在内容特征上接近
样式损失使合成图片与样式图片在样式特征上接近
全变分损失有助于减少合成图片中的噪点
2、可以通过预训练好的卷积神经网络来抽取图像的特征，并通过最小化损失函数来不断更新合成图片来作为模型参数

3、使用格拉姆矩阵表达样式层输出的样式









Q&A



1、越靠近输出端内容还原度越高还是越靠近输入端内容还原度越高？style、content 层的选取是不是也是根据经验？
﻿
QA P3 - 00:00
﻿


2、为什么这地方不需要算梯度，y.detach()，是因为网络不更新，只有输入更新吗？
﻿
QA P3 - 00:26
﻿



3、二、三、四、五阶统计信息有哪些啊？
﻿
QA P3 - 01:05
﻿


4、协方差矩阵、格莱姆矩阵、统计直方图这三个之间是相互包含吗？都能代表样式？
﻿
QA P3 - 01:30
﻿


5、老师，TV 损失可以理解为图像平滑技术吗？
﻿
QA P3 - 02:07
﻿


6、为什么卷积层的 kernel 不需要参加训练？
﻿
QA P3 - 02:15
﻿


7、更新的权重是对图片的，那模型的权重是在哪里训练的？
﻿
QA P3 - 02:33
﻿


8、核心优化的是一个参数矩阵？每做一张图片的风格迁移，都要重新训练一遍？有什么方法能一劳永逸吗？
﻿
QA P3 - 03:11
﻿


9、语义分割是不是也可以用样式迁移来实现，原图是内容， label 是样式图片
﻿
QA P3 - 04:48
﻿


10、样式迁移目前有很广泛的商业价值应用吗？是不是因为不怎么能产品化，大家现在不怎么玩了
﻿
QA P3 - 05:11
﻿


11、是不是也可以用领域自适应常用的 mdd 距离度量
﻿
QA P3 - 06:34
﻿


12、RNN 和一维卷积区别大吗？
﻿
QA P3 - 06:44
﻿


13、会介绍 GAN 吗？
﻿
QA P3 - 06:52
﻿


14、新的目标检测竞赛什么时候？
﻿
QA P3 - 07:26
﻿








----end----

其他参考

1、《动手学深度学习》，PPT，https://courses.d2l.ai/zh-v2/assets/pdfs/part-2_17.pdf

2、《动手学深度学习》，教材，https://zh-v2.d2l.ai/chapter_computer-vision/neural-style.html 作者：如果我是泡橘子 https://www.bilibili.com/read/cv17602698/?from=readlist&jump_opus=1 出处：bilibili