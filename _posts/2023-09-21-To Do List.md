---
published: false
layout: post
title: "0.序"
categories: 我的AI新书
banner:
  video: https://vjs.zencdn.net/v/oceans.mp4
  loop: true
  volume: 0.8
  start_at: 8.5
  image: https://bit.ly/3xTmdUP
  opacity: 0.618
  background: "#000"
  height: "100vh"
  min_height: "38vh"
  heading_style: "font-size: 4.25em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
excerpt: "序"
top: 2

---

**是否能使用RadImageGAN，BigDatasetGAN生成MRI 头部数据用于训练胼胝体分割模型？**

RadImageNet，RadImageGAN，BigDatasetGAN是三个不同的项目，它们之间的联系是都涉及到了医学图像的生成和分析。具体来说：

- RadImageNet 是一个开放的医学图像数据库，包含了135万张CT、MRI和超声波图像，涵盖了多种器官和病理。RadImageNet还提供了一些预训练的卷积神经网络，可以用于医学图像的迁移学习。RadImageNet的目的是为医学图像人工智能应用提供一个有效的数据集和基准模型。
- RadImageGAN是一个基于GAN（生成对抗网络）的医学图像生成模型，可以从噪声中生成高质量的CT、MRI和超声波图像。RadImageGAN使用了RadImageNet作为训练数据，利用了GAN的强大能力来模拟真实的医学图像分布。RadImageGAN的目的是为医学图像增强、数据增广、模拟和教育等场景提供一个有用的工具。
- BigDatasetGAN是一个基于GAN的大规模数据集生成模型，可以从少量的样本中生成大量的新样本。BigDatasetGAN使用了一种新颖的自监督学习方法，结合了对比学习和循环一致性损失，来提高GAN的稳定性和多样性。BigDatasetGAN可以用于任何类型的数据集，包括医学图像、自然图像、文本等。BigDatasetGAN的目的是为数据稀缺或隐私敏感的领域提供一个有效的数据集扩充方法。




https://www.youtube.com/watch?v=byNaO_zn2fI  how to self study pure math



https://www.youtube.com/watch?v=NHszJiL-9pM   Generative AI in Biology and HealthCare



https://www.youtube.com/watch?v=q6kJ71tEYqM machine learning VS deep learning



https://catalog.ngc.nvidia.com/orgs/nvidia/teams/playground/models/clip Nvidia CLIP在线PlayGround


**如何在UNET中添加注意力机制的？**



**基于AI的图像生成路线**
基于AI的图像生成技术是指利用人工智能技术，根据给定的数据或条件，生成新的图像的过程。这种技术有很多应用领域，例如平面设计、游戏制作、动画制作、医学影像、化合物合成等。目前，主流的图像生成技术主要有以下几种：

- 生成对抗网络（GAN）：这是一种利用两个神经网络进行博弈训练，使生成器能够产生逼真的图像的方法。GAN有很多变种和改进，例如条件GAN、自编码器GAN、循环GAN等。
- 扩散模型（Diffusion Model）：这是一种通过向数据添加随机噪声，然后逐步去除噪声来生成图像的方法。扩散模型能够更好地保留图像细节和真实性，但也存在采样速度慢和泛化能力弱的问题。
- 自回归模型（Autoregressive Model）：这是一种利用Transformer结构中的自注意力机制来对图像进行逐像素生成的方法。自回归模型能够提高图像生成的准确性和合理性，但也存在推理速度慢和训练成本高的问题。
AE-DAE-VAE-VQVAE
- 对比学习模型（Contrastive Learning Model）：这是一种利用文本-图像跨模态预训练来建立文本和图像之间的联系的方法。对比学习模型能够根据文本描述生成符合语义的图像，同时提高图像的多样性和风格化。
以上是我从网上搜索到的一些关于基于AI的图像生成技术的信息123




**The worlds I see by Li Fei Fei**
Commented by Geoffrey Hinton
Fei-Fei Li has written a book. She was the first computer vision researcher to truly understand the power of big data and her work opened the floodgates for deep learning. She delivers a clear-eyed account of the awesome potential and danger of AI.


**集成了GPT4和DALLE-3的好网站**
https://rochat.ai/




**2023基于胼胝体分割的自动定位像任务**
原始PaddlePaddle版本2.1.2和PaddleSeg版本2.4.0

2023.11.14号，PaddlePaddle版本2.4.0和PaddleSeg版本2.6.0，python版本3.7，状态：成功

一定要去官方网站查PaddlePaddle和PaddleSeg的匹配情况

通过下面代码支持导出动态输入大小的C++推理模型，但输入图像尺寸不能相差太大，否则会影响效果。
from paddleseg.models import BiSeNetV2
model = BiSeNetV2(num_classes=2,
                 lambd=0.25,
                 align_corners=False,
                 pretrained='/home/aistudio/Myoutput2/best_model/model.pdparams')
model.eval()
from paddle.static import InputSpec
import paddle
path = 'func/model'
paddle.jit.save(
    model,
    path,
    input_spec=[
        InputSpec(
            shape=[1,3, -1,-1], dtype='float32', name='x'),
    ])


**全脊柱拼接ROI如何支持旋转**




1.如何通过mousedown，mousemove，moouseup计算鼠标绕某个中心点的旋转角度
假设我们要计算鼠标围绕中心点 (cx, cy) 的旋转角度,可以这么实现:

在mousedown时,记录起始点位置(x1, y1)
在mousemove时,获取当前点位置(x2, y2)
计算起始点到中心点的向量v1 = (x1 - cx, y1 - cy)
计算当前点到中心点的向量v2 = (x2 - cx, y2 - cy)
使用向量叉积计算两个向量的夹角:
js

Copy code

let v1 = [x1 - cx, y1 - cy];
let v2 = [x2 - cx, y2 - cy];

let cross = v1[0]*v2[1] - v1[1]*v2[0];
let angle = Math.atan2(cross, v1[0]*v2[0] + v1[1]*v2[1]);
在mouseup时,angle就是鼠标拖拽的总旋转角度
将弧度转为角度的方法同上
这种方法通过计算向量之间的叉积,可以很好地处理鼠标围绕中心点的旋转角度计算。

2.单独旋转定位框
// 创建Graphics对象
Graphics g = this.CreateGraphics();

// 保存当前坐标系统 
g.Save();

// 旋转坐标系45度
g.RotateTransform(45);  

// 绘制旋转后的矩形
g.DrawRectangle(Pens.Black, 100, 100, 200, 100);

// 恢复坐标系统
g.Restore();

或者使用
// 旋转角度
double angle = 45;

// 计算旋转矩阵
double cos = Math.Cos(angle);
double sin = Math.Sin(angle);
double[,] rotateMatrix = {
    {cos, -sin},
    {sin, cos}
};

// 矩形的4个顶点
Point[] points = { new Point(100, 100), new Point(300, 100), 
                   new Point(300, 200), new Point(100, 200) };

// 变换顶点坐标
for (int i = 0; i < 4; ++i)
{
    double x = points[i].X;
    double y = points[i].Y;
    points[i].X = x * cos - y * sin;
    points[i].Y = x * sin + y * cos;
}

// 绘制变换后的矩形
g.DrawPolygon(Pens.Black, points);

或者
GraphicsPath path = new GraphicsPath();
path.AddRectangle(new Rectangle(100, 100, 200, 100));

// 设置旋转矩阵
Matrix m = new Matrix();
m.Rotate(45);
path.Transform(m);

// 绘制路径  
g.DrawPath(Pens.Black, path);



https://youtu.be/Q1yu6TQZ79w?si=rSVPrfz-QIulE8pi 假设检验
https://youtu.be/c06FZ2Yq9rk?si=tdVHRyc3WHvFmwwa 概率基础知识
https://youtu.be/xTpHD5WLuoA?si=A6Y0hQJEBcs4snYM 相关性和回归


https://mp.weixin.qq.com/s/_n63gt7lRZdiaZGFIk4-fQ  十大优化算法


C++Release模式下断点调试：
调试信息格式：程序数据库 (/Zi)
关闭优化
生成调试信息


**3D动画制作工具**
开源免费
Blender
https://github.com/blender/blender?tab=readme-ov-file


**与Blender一样开源免费的工具还有哪些，并给出一个排名**

与Blender类似的开源且免费的3D制作工具包括:

Blender:功能完善,社区活跃,插件丰富,被誉为3D创作的瑞士军刀。
MakeHuman:专注于人物建模和人脸渲染。逼真的人体和面部特征使其在人物创作领域排名第二。
Wings 3D:操作简单易上手。虽然功能不如Blender,但轻量化的界面吸引了许多初学者。
MeshLab:聚焦于3D模型处理和编辑。可进行网格修复、渲染、纹理化等,但不含建模工具,被广泛用作模型后期处理工具。
OpenSCAD:使用编程语法进行各种几何体的建模。容易实现参数化建模和迭代优化,适用于工程和机械建模。
Daz Studio:侧重人物角色设计,提供大量预制资产。易上手但扩展性不如Blender。
综合功能、社区支持以及应用范围,Blender可以被公认为最佳开源免费3D制作工具。其余工具各有侧重,搭配Blender可发挥更大作用。

**Cinema 4D和Blender有什么区别？**
Cinema 4D和Blender都是很流行的3D建模和动画软件,主要有以下几点区别:

价格:Cinema 4D需要购买授权,价格昂贵,而Blender是开源免费软件。
操作界面:Cinema 4D的界面更加简洁干净,上手较为容易。Blender的界面更复杂,功能更丰富,学习曲线更加陡峭。
渲染能力:Cinema 4D自带的物理渲染器更加专业和易用。Blender需要依赖第三方渲染器,但功能也很强大。
视觉效果:Cinema 4D更擅长商业级的动画和视觉特效。Blender在角色、静态场景更占优势。
扩展能力:Blender的Python API非常强大,可以无限扩展。Cinema 4D的插件系统也比较成熟。
工作流:Cinema 4D与After Effects的联动更加紧密。Blender需要转换格式,轮廓也不如C4D稳定。
总的来说,Cinema 4D商业化程度更高,Blender更注重开源社区。喜欢自由开源的选Blender,想要简单好用的商业软件选C4D。

**在3D动画制作过程中，Modeling，Rendering，Shading的区别**
在3D动画的制作流程中,Modeling、Rendering和Shading这三个概念区别如下:

Modeling(建模)
指使用3D软件创建物体的几何形状和物理结构的过程。包括人物、场景、道具等的3D模型都需要经过建模师的Modeling。

Rendering(渲染)
指计算机根据模型的几何结构、材质、颜色、光照等数据,生成2D图像的过程。常见的渲染技术有光线追踪、路径追踪等。这是动画最终形成画面的关键步骤。

Shading(着色)
指为3D模型赋予材质、贴图和灯光效果的过程,以实现最终的视觉表现。涉及有色调、纹理、明暗、高光等方面。这在渲染前决定了最终效果的样子。

简单来说,Modeling决定了几何形状,Rendering生成图像,Shading实现视觉表现。它们是3D动画制作的三大基础环节。


**当我们说一台电脑是否支持OpeGL时，指的是操作系统还是CPU还是GPU硬件？**
当我们说一台电脑是否支持OpenGL时，指的是显卡（GPU）硬件和驱动程序是否支持OpenGL的特定版本。OpenGL是一个开放的图形库，它提供了一系列的接口，用于绘制2D和3D图形。不同的显卡和驱动程序可能支持不同的OpenGL版本，这会影响到一些图形应用程序的运行效果。如果您想知道您的电脑支持哪个版本的OpenGL


**不用图像函数库，仅用纯C#语言实现一个图像平移操作，使用双线性插值**
using System;
					
public class ImageTranslator {

  // Input image pixels
  private double[,] inputPixels;	
  private int width;
  private int height;

  // Output translated image pixels
  private double[,] outputPixels;
	
  // Translation distances  
  private double dx; 
  private double dy;

  public ImageTranslator(double[,] input, int w, int h) {
    inputPixels = input;
    width = w;  
    height = h;
  }

  // Set translation distance 
  public void SetTranslation(double x, double y) {
    dx = x;  
    dy = y;
    outputPixels = new double[width, height]; 
  }

  // Bilinear interpolation implementation
  private double Interpolate(double x, double y) {
    int x1 = (int) x;
    int x2 = x1 + 1;
    int y1 = (int) y;
    int y2 = y1 + 1;
		
    double f11 = GetPixel(x1, y1);
    double f12 = GetPixel(x1, y2);
    double f21 = GetPixel(x2, y1);
    double f22 = GetPixel(x2, y2);

    double fxy = (x2 - x) / (x2 - x1) * f11 + (x - x1) / (x2 - x1) * f21 + 
               (x2 - x) / (x2 - x1) * f12 + (x - x1) / (x2 - x1) * f22; 

    return fxy; 
  }

  private double GetPixel(int x, int y) {
    if (x < 0 || x >= width || y < 0 || y >= height)  
      return 0;	
    else
      return inputPixels[x, y];	
  }

  // Translate image 	
  public void TranslateImage() {				
    for (int x = 0; x < width; x++) {
      for (int y = 0; y < height; y++) {	
        double newX = x + dx;	
        double newY = y + dy;
        outputPixels[x, y] = Interpolate(newX, newY);  
      }
    }
  } 	
}


**20231229**
1.制作VR DICOM视频，上传到视频号
2.学习Hololens 2开发流程 youtube
3.自然语言处理入门 pdf，加强NLP基础
4.面向数据科学家的使用统计学 pdf，加强数据科学的基础



**20240102**
LLM Fine-Turning and Prompt Engineering White Papers
LLM Training


**20240103**
Speech Recognition：parakeet beats Whispe


**20240104**
微信公众号：万字通俗讲解大语言模型内部运行原理
https://www.understandingai.org/p/large-language-models-explained-with


**20240105**
Understand DeepLearning :12 Transformer and LLM
Sliders发微信公众号

https://huggingface.co/spaces/modelscope/AnyText：文本生成图片


神经辐射场NeRF

**20240108**
ChatGPT：Explained to kids
Understanding deeplearning :Chapter12 Transformer
欧姆社漫画机器学习系列

**20240109**
商君书：贫，疲，辱，弱，愚
墙：域名污染，IP:端口连接重置
【一起学AI】 6-AI就那点事:图像，表格

字节跳动版GPTs：Coze
试玩了一些模型

凯文凯利-失控 AI解读


根据我从网络上搜索到的信息，截止到2023年，中国一共有3275家三级医院，其中1651家是三级甲等医院，以及10848家二级医院


**20240110**
图像放大和增强
https://magnific.ai/
【一起学AI】 6-AI就那点事:文字，需要学习

98年房改，国有土地可以出让，土地财政，土地金融，房地产拉开序幕

计算机科学地图

小Lin说上市
好处：融资，套现，知名度，降低再融资门槛
坏处：股权稀释，信息公开，维护成本，上市周期
A股：大陆人民币股，上交所，北交所，深交所
3D扫描仪：输出点云，网格等

**20240111**
小Lin说游戏产业
游戏产业链
![不同游戏设备市场大小]({{ "assets/images/小Lin说/不同游戏设备市场大小.png" | relative_url }})

![游戏产业链]({{ "assets/images/小Lin说/游戏产业链.png" | relative_url }})

小Lin说英伟达
3D游戏
挖矿
人工智能
大模型

小Lin说退市
资源退市：重组，调整经营方向
强制退市：经营，违法

小Lin说Web3.0
Web1.0
1991年诞生：只读
搜狐
yahoo

Web2.0
2004年诞生：可写，可交互，留言，评论
FaceBook
电报
youtube

用户信息推送广告赚钱

Web3.0
信息不想被泄漏
区块链


**20240112**
编译gglm clip
Linux GNU支持可变长数组，MSVC不支持
编译whisper.cpp和whisper.net



AI+,即将AI作为核心技术与其它行业进行深度融合，随着生成式AI的出现，尤其是大语言模型，AI+也将步入一个新台阶。
与基础大模型相比，AI+更适合垂类大模型。

AI+医疗，更进一步，AI+医疗影像。

SAM：分割，标注
Whisper：语音识别，电子病历
CLIP：多模态
LLAMA：Chatbot，医生助理


**20240115**
深度学习革命
llama以及微调

**20240116**
深度学习革命
bert以及微调


**20240117**
深度学习革命
PhotoMaker
BLIP:图生文，Coca，BeiT


**20240118**
多模态论文
Transformer：从0开始
https://nlp.seas.harvard.edu/annotated-transformer/
.NetFramework中录音
https://github.com/naudio/NAudio 


**20240119**
AlphaGeometry 


**20240122**
Elucis: the VR platform for creating, visualizing, manipulating, and discussing patient-specific 3D medical models.

Hugging Face：Transformer

三种Tokenlization的优缺点：
https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt


**20240123**
李宏毅 Transformer
https://www.bilibili.com/video/BV1v3411r78R

LLM技术路线：
https://github.com/mlabonne/llm-course?tab=readme-ov-file

LLM可视化：
https://bbycroft.net/llm


**20240124**
NamePipe client server
how chatGPT is trained?

西蒙普林斯推荐的书：
https://shepherd.com/best-books/machine-learning-and-deep-neural-networks

Probabilistic Machine Learning: An Introduction
https://probml.github.io/pml-book/book1.html


**20240125**
anylabeling
llama 2

Probabilistic Machine Learning chapt 8 细节搜索


**20240126**
Probabilistic Machine Learning: Advanced topics
https://probml.github.io/pml-book/book2.html

书的目录
由粗到细 coase to fine

CheXAgent:医疗领域多模态大模型
https://stanford-aimi.github.io/chexagent.html

Yann LeCun, Yoshua Bengio& Geoffrey Hinton
论文：DeepLearning

传统机器学习不擅长处理自然数据：图像，文本


所有大佬唯一留在学术界，坚持开源开放思想的人。
Yoshua Bengio所有资料
https://yoshuabengio.org/presentations/


**20240218**
图解机器学习
https://www.theinsaneapp.com/2021/11/machine-learning-algorithms-for-beginners.html

**diffusion-explainer**
https://poloclub.github.io/diffusion-explainer/

**各种可视化**
https://poloclub.github.io/

**CNN可视化**
https://adamharley.com/nn_vis/cnn/3d.html
https://github.com/aharley/nn_vis

**Vison Pro**
https://twitter.com/SteveFlanders22/status/1758491479461581211


**20240219**
langChain
ChatGLM
RAG

**20240220**
涌现
漫画趣味化学，物理，数学，语文启蒙书
倒排索引：搜索
Faiss：Facebook AI Similarity Search 快速向量相似性搜索

从openai提供的接口出发，看这些接口

llama-index ：创建数据索引

向量数据库

LangFlow:界面版LangChain


**20240221**
FreeSurfer：开源的MRI头部处理软件
找分割MRI胼胝体
https://github.com/freesurfer/freesurfer
https://surfer.nmr.mgh.harvard.edu/

B1 bias field correction 是一种用于改善磁共振图像质量的方法，它可以消除由磁场不均匀性导致的图像亮度变化。这种变化会影响图像中的组织对比度和灰度值，从而干扰图像分析和处理。B1 bias field correction 的原理是通过估计和除去图像中的偏置场（bias field），从而恢复图像的真实信号。B1 bias field correction 的方法有很多，例如基于信号模型和先验假设的传统方法，或者基于深度学习的数据驱动方法。如果您想了解更多关于 B1 bias field correction 的信息。

SynthStrip: Skull-Stripping for Any Brain Image
https://surfer.nmr.mgh.harvard.edu/docs/synthstrip/

https://github.com/freesurfer/freesurfer/tree/dev/mri_watershed

itk-snap
开源并且包括颅骨剥离算法


