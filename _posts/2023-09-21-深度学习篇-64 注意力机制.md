---
published: false
layout: post
title: "预告"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "预告"
---


注意力机制





从心理学的角度出发



动物需要在复杂的环境下有效地关注值得注意的点

心理学框架：人类根据随意线索（主动、有意识）和不随意线索选择注意点








注意力机制



卷积、全连接、池化层都只考虑不随意线索（没有明确的目标）

池化操作通常是将感受野范围中的最大值提取出来（最大池化）
卷积操作通常是对输入全部通过卷积核进行操作，然后提取出一些比较明显的特征




注意力机制是显式地考虑随意线索

随意线索被称之为查询（query）---- 所想要做的事情
每个输入是一个值（value）和不随意线索（key）的对 ---- 可以理解为环境，就是一些键值对，key 和 value 可以相同，也可以不同
通过注意力池化层来有偏向性地选择某些输入 ---- 根据 query 有偏向地选择输入，跟之前的池化层有所不同，这里显式地加入了 query，然后根据 query 查询所需要的东西








非参注意力池化层




非参：不需要学习参数
x -- key
y -- value
f（x）-- 对应所要查询的东西
（x，y） -- key-value对（候选）
平均池化：之所以是最简单的方案，是因为不需要管所查询的东西（也就是f（x）中的 x ），而只需要无脑地对 y 求和取平均就可以了




Nadaraya-Watson 核回归：

核：K 函数，它可以认为是衡量 x 和 xi 之间距离的函数
数据就是给定的数据，对于新给定的值来讲，只需要在给定的数据中进行查询就可以了（选择和新给定的值比较相近的数据，然后将这些数据对应的 value 值然后进行加权求和，从而得到最终的 query），所以不需要学习参数


K 的选择：高斯核


u：代表 x 和 xi 之间的距离
exp：作用是将最终的结果变成大于 0 的数
softmax：得到 0 到 1 之间的数作为权重
在上式的基础上添加一个可以学习的 w ：









总结



1、心理学认为人通过随意线索和不随意线索选择注意点



2、注意力机制中，通过query（随意线索）和 key（不随意线索）来有偏向性地选择输入，一般可以写作


f（x）的 key 和所有的不随意线索的 key 做距离上的计算（α（x，xi），通常称为注意力权重），分别作为所有的 value 的权重
这并不是一个新兴的概念，早在 60 年代就已经有非参数的注意力机制了








----end---- 作者：如果我是泡橘子 https://www.bilibili.com/read/cv15803971/?from=readlist&jump_opus=1 出处：bilibili