---
published: false
layout: post
title: "预告"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "预告"
---


AlexNet



在LeNet提出后，卷积神经网络在计算机视觉和机器学习领域中很有名气，但卷积神经网络并没有主导这些领域，因为虽然LeNet在小数据集上取得了很好的效果，但是在更大、更真实的数据集上训练卷积神经网络的性能和可行性还有待研究
引起这一个深度学习热潮的第一个网络
AlexNet诞生于2012年，与另一种观察图像特征的提取方法不同，它认为特征本身应该被学习，在合理的复杂性前提下，特征应该由多个共同学习的神经网络层组成，每个层都有可学习的参数。在机器视觉中，最底层可能检测边缘、颜色和纹理；更高层建立在底层表示的基础上，以表示更大的特征，更高层可以检测整个物体；最终的隐藏神经元可以学习图像的综合表示，从而使不同类别的数据易于区分




深度学习之前的网络

﻿
AlexNet P1 - 00:33
﻿

事实上，在上世纪90年代初到2012年之间的大部分时间里，神经网络往往被其他机器学习方法超越，如支持向量机（support vector machines）
传统机器学习方法中，机器视觉流水线是由经过人的手工精心设计的特征流水线组成的；在神经网络中，卷积神经网路的输入是由原始像素值或者是经过简单预处理（例如居中、缩放）的像素值组成的
2000年的时候，最火的机器学习的方法其实是核方法

这张图中展示的是2000年初期最主要使用的方法
核心是：提取特征、选择核函数来计算相关性（如何判断两个点在高维空间上是相关的，如果是线性的话可以做内积，用核方法的话可以通过变换空间，将空间变换成想要的样子）、凸优化问题（通过和函数计算之后就会变成一个凸优化问题，线性模型型是一个凸优化问题，所以它有很好的理论解，可以将显式解写出来）、漂亮的定理（因为是凸优化，所以有比较好的定理）
整个核方法最大的特色就是有一个完整的数学定理，能够计算模型的复杂度等，这也是为什么在2000年的时候核方法能够替代深度学习（当时叫神经网络）成为当时机器学习主流的网络








在2000年左右机器学习主要关心的是几何学﻿
AlexNet P1 - 03:11
﻿










十几年前，在计算机视觉中最重要的其实是特征工程

在2012年之前，图像特征都是机械地手动计算出来的，例如常见的特征函数：SIFT、SURF、HOG（定向梯度直方图）和类似的特征提取方法


﻿
AlexNet P1 - 05:40
﻿


整个计算机视觉在深度学习之前其实不那么关心机器学习的模型长什么样子，关键是如何做特征提取，怎样抽取特征使得机器学习能够比较好地学习特征








神经卷积网络取得突破的两大关键因素



1、硬件



深度学习对计算资源要求很高，训练可能需要数百个迭代轮数，每次迭代都需要通过代价高昂的许多线性代数层传递数据。这也是为什么在20世纪90年代至21世纪初，优化凸目标的简单算法是研究人员的首选。
虽然上世纪90年代就有了一些神经网络加速卡，但仅靠它们还不足以开发出有大量参数的深层多通道多层卷积神经网络。此外，当时的数据集仍然相对较小。除了这些障碍，训练神经网络的一些关键技巧仍然缺失，包括启发式参数初始化、随机梯度下降的变体、非挤压激活函数和有效的正则化技术。
AlexNet使用了两个显存为3GB的NVIDIA GTX580 GPU实现了快速卷积运算
﻿
AlexNet P1 - 07:13
﻿


图中三行分别是：样本个数、内存大小、CPU计算能力
计算能力和数据所要的算法能力的发展的不同阶段导致对网络选取的偏好差异




2、数据



深度学习的再次崛起离不开数据
包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法（如线性方法和核方法）
ImageNet数据集由斯坦福教授李飞飞小组的研究人员开发，利用谷歌图像搜索（Google Image Search）对每一类图像进行预筛选，并利用亚马逊众包（Amazon Mechanical Turk）来标注每张图片的相关类别。这种规模是前所未有的


ImageNet数据集


上图是ImageNet数据集和MNIST数据集的对比








AlexNet

2012年拿到了ImageNet竞赛2012年的冠军
Alex本质上是一个更深、更大的LeNet，二者在架构上没有本质的区别，主要的改进在于：1、加入了丢弃法；2、激活函数从sigmoid改成了ReLu；3、池化操作从Avgpooling改成了MaxPooling
丢弃法可以认为是用来做模型控制，因为模型更大了，所以可以使用丢弃法来做正则
ReLu和sigmoid相比，它的梯度确实更大，而且ReLu在零点处的一阶导更好，能够支撑更深的模型
MaxPooling取的是最大值，使得输出比较大，梯度也比较大，从而使得训练而更加容易
AlexNet不仅仅是更大、更深，更加关键的是观念上的改变：LeNet仅仅被认为只是一个机器学习的模型，但是AlexNet增加了几十倍，量变引起质变，引起了计算机视觉方法论的改变，原本机器学习的专家对于问题的理解主要放在对特征的人工提取上

上图左边主要关注点在于SVM需要怎样的特征，右边是一个一起训练的过程（最后的分类器和特征提取的模型是一起训练的，也就意味着CNN学出来的东西很有可能就是softmax所想要的，通过很深的神经网络将原始的像素转换到一个空间当中，使得softmax能够更好地进行分类）
这样做的好处是：1、构造CNN相对来说比较简单，而不需要了解太多计算机视觉相关的知识，而且比较容易跨问题、跨学科；2、因为分类器和特征提取的模型是一起训练的，从模型角度来讲，其实就是一个，这样做更加高效
深度学习对之前传统的机器学习的主要改变：不在执着于怎样进行人工提取特征，而是端到端的学习过程，使得原始的信息到最后的分类或者预测可以直接通过深度神经网络实现








AlexNet和LeNet的对比


左图表示LeNet，右图表示AlexNet








AlexNet










AlexNet其实就是一个更大、更深的LeNet，由八层组成：5个卷积层、2个全连接隐藏层和一个全连接输出层
AlexNet的输入是224*224*3的3通道RGB图片，LeNet的输入是32*32*1的单通道灰度图片
第一层：AlexNet使用了更大的核窗口（因为图片更大了，需要用更大的卷积窗口来捕获目标），通道数也更多了，从6变成了96（希望能够在第一层识别更多的模式，所以用了比较大的通道数），stride从2变成了4（这是由于当时GPU性能的限制，如果stride比较小的话，计算就会变得非常困难）
第二层：AlexNet使用了更大的池化层，stride都是2，因为LeNet的池化层窗口大小也是2，所以它每次看到的内容是不重叠的。2*2和3*3的主要区别是：2*2允许一个像素往一边平移一点而不影响输出，3*3的话就允许一个像素左移或者右移都不影响输出；stride都等于2使得输出的高和宽都减半
第三层：AlexNet有一个padding为2的操作，它的作用就是使得输入和输出的大小是一样的；AlexNet的输出通道是256，使用了更多的输出通道来识别更多的模式
ALexNet新加了3个卷积层
AlexNet的全连接层也用了两个隐藏层，但是隐藏层更大（在最后一个卷积层后有两个全连接层，分别有4096个输出。 这两个巨大的全连接层拥有将近1GB的模型参数。 由于早期GPU显存有限，原版的AlexNet采用了双数据流设计，使得每个GPU只负责存储和计算模型的一半参数）
Alex的激活函数从sigmoid变成了ReLu：1、ReLU激活函数的计算更简单，它不需要sigmoid激活函数那般复杂的求幂运算；2、当使用不同的参数初始化方法时，ReLU激活函数使训练模型更加容易；3、、当sigmoid激活函数的输出非常接近于0或1时，这些区域的梯度几乎为0，因此反向传播无法继续更新一些模型参数，相反，ReLU激活函数在正区间的梯度总是1。 因此，如果模型参数没有正确初始化，sigmoid函数可能在正区间内得到几乎为0的梯度，从而使模型无法得到有效的训练。
LeNet只使用了权重衰减，而AlexNet在全连接层的两个隐藏层之后加入了丢弃层（dropout、暂退法），来做模型的正则化，控制全连接层的模型复杂度
为了进一步扩充数据，AlexNet还做了数据的增强：对样本图片进行随机截取、随机调节亮度、随即调节色温（因为卷积对位置、光照等比较敏感，所以在输入图片中增加大量的变种，来模拟预测物体形状或者颜色的变化；因为神经网络能够记住所有的数据，通过这种变换之后来降低神经网络的这种能力，因为每次变换之后的物体都是不一样的）




AlexNet和LeNet模型的复杂度对比﻿
AlexNet P1 - 30:49
﻿


AlexNet使用了7*7的卷积核，而且通道数增加了，所以参数个数增加的比较多
AlexNet在可学习的参数个数上比LeNet多十倍左右
FLOP：每秒所执行的浮点运算次数（floating-point operations per second）








总结



AlexNet是更大更深的LeNet，但是整个架构是一样的，AlexNet的参数个数比LeNet多了10倍，计算复杂度多了260倍
AlexNet新加入了一些小技巧使得训练更加容易：丢弃法（dropout）、ReLu、最大池化层、数据增强
AlexNet首次证明了学习到的特征可以超越手工设计的特征，以很大的优势赢下了2012年的ImageNet竞赛之后，标志着新一轮的神经网络热潮的开始
尽管今天AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步
Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤








Q&A



ImageNet数据集是怎么构建的，现在看是不是要成为历史了？﻿
QA P3 - 00:03
﻿


为什么2000年的时候，神经网络被核方法所代替？是因为神经外罗计算量太大，数据多，硬件跟不上吗？﻿
QA P3 - 00:52
﻿


nlp领域，cnn也代替了人工特征工程吗？如何看待nlp领域transformer、bert、deepfm这些方法和cv领域cnn方法的区别？﻿
QA P3 - 01:12
﻿


AlexNet让机器自己寻找特征，这些找到的特征都符合人类的逻辑吗？如果不符合的话，要怎么解释？﻿
QA P3 - 01:33
﻿


把AlexNet的池化层放到不同的卷积层后面，效果一样吗？或者为什么放在第一个和最后一个卷积层后面？﻿
QA P3 - 02:44
﻿


这两个网络的设计除了看论文，有没有其他方式了解到作者们的具体设计过程？﻿
QA P3 - 03:28
﻿


从发展视角来看，CNN完爆MLP吗？未来MLP是否有可能由于某些技术成为主流？﻿
QA P3 - 04:32
﻿


在其他学习资料中，讲到AlexNet会提及Local Response Normalization，但没太看懂。老师能补充讲解一下LRN的原理以及如何达成“增强了模型的泛化能力”的效果吗？﻿
QA P3 - 05:03
﻿


为什么AlexNet最后要有两个相同的全连接层Dense（4096）？一个行吗？﻿
QA P3 - 06:20
﻿


我们现在讲的内容是不是只适用于nlp和cv领域，在推荐领域是不是不适用？﻿
QA P3 - 06:57
﻿


我们在一个识别细胞的程序里做了颜色+几何变换的增强后效果反倒比只做几何变化的增强效果差。这个可能是因为什么？﻿
QA P3 - 07:36
﻿


AlexNet和LeNet的参数对比PPT是不是写错了，参数个数是460M vs 0.6M，不是11x吧？﻿
QA P3 - 08:21
﻿


没太明白为什么LeNet不属于深度卷积神经网络？﻿
QA P3 - 09:00
﻿


老师，在设计网络结构的时候，conv、全连接、dropout、池化这些层，包括后来出现的bn，这些层的先后顺序有什么讲究吗？有没有什么经典的设计思路？﻿
QA P3 - 11:34
﻿


为什么要有dropout，能提高计算性能吗？﻿
QA P3 - 11:57
﻿


作为一个门外汉，感觉现在新的CV领域模型越来越少，大家都在搞demo，老师如何看待这个事情？﻿
QA P3 - 12:10
﻿


网络要求输入的size是固定的，实际使用的时候图片不一定是要求的size，如果强行resize成网络要求的size，会不会最后的效果要差？﻿
QA P3 - 14:02
﻿


AlexNet和LeNet为什么在后面都加全连接层，从参数量来看全连接层占了绝大多数，作用有没有那么大？﻿
QA P3 - 15:15
﻿


AlexNet为什么新增加了3层384输出的卷积层，是有什么理论或者道理吗？为什么不增加5层或者更多/更少层卷积？这种网络的设计是通过多次尝试试出来的？还是有什么理论基础支撑选择设计呢？﻿
QA P3 - 15:27
﻿








----end----

其它参考：

1、《动手学深度学习》PPT，https://courses.d2l.ai/zh-v2/assets/pdfs/part-1_8.pdf

2、《动手学深度学习》，https://zh-v2.d2l.ai/chapter_convolutional-modern/alexnet.html 作者：如果我是泡橘子 https://www.bilibili.com/read/cv15288377/?from=readlist&jump_opus=1 出处：bilibili