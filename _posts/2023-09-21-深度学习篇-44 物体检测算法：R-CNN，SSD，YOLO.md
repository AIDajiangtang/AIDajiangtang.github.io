---
published: false
layout: post
title: "预告"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "预告"
---


目标检测中的常用算法





1、区域卷积神经网络(region-based CNN or regions with CNN features)



除了 SSD 之外，区域卷积神经网络也是深度模型应用于目标检测的开创性工作之一


R-CNN（基于区域的卷积神经网络）﻿
目标检测 P1 - 00:09
﻿



R-CNN系列中最早的模型



首先从输入图像中选取若干个提议区域（锚框是选取方式的一种），并标注它们的类别和边界框（如偏移量）。然后用卷积神经网络来对每个提议区域（锚框）进行前向传播以抽取特征。最后用每个提议区域的特征来预测类别和边界框。


R-CNN 模型的四个步骤：

对输入图像使用选择性搜索来选取多个高质量的提议区域。这些提议区域通常是在多个尺度下选取的，并具有不同的形状和大小；每个提议区域都将被标注类别和真实边框
选择一个预训练的卷积神经网络，并将其在输出层之前截断。将每个提议区域变形为网络需要的输入尺寸，并通过前向传播输出抽取的提议区域特征
将每个提议区域的特征连同其标注的类别作为一个样本。训练多个支持向量机对目标分类，其中每个支持向量机用来判断样本是否属于某一个类别
将每个提议区域的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框




每次选择的锚框的大小是不同的，在这种情况下，怎样使这些大小不一的锚框变成一个batch？

RoI pooling（兴趣区域池化层）

R-CNN 中比较关键的层，作用是将大小不一的锚框变成统一的形状
给定一个锚框，先将其均匀地分割成 n * m 块，然后输出每块里的最大值，这样的话，不管锚框有多大，只要给定了 n 和 m 的值，总是输出 nm 个值，这样的话，不同大小的锚框就都可以变成同样的大小，然后作为一个小批量，之后的处理就比较方便了

上图中对 3 * 3 的黑色方框中的区域进行 2 * 2 的兴趣区域池化，由于 3 * 3 的区域不能均匀地进行切割成 4 块，所以会进行取整（最终将其分割成为 2 * 2、1 * 2、2 * 1、1 * 1 四块），在做池化操作的时候分别对四块中每一块取最大值，然后分别填入 2 * 2 的矩阵中相应的位置


兴趣区域汇聚层（RoI Pooing）与一般的汇聚层有什么不同？

在一般的汇聚层中，通过设置汇聚窗口、填充和步幅的大小来间接控制输出形状
在兴趣区域汇聚层中，对每个区域的输出形状是可以直接指定的




小结



尽管 R-CNN 模型通过预训练的卷积神经网络有效地抽取了图像特征，但是速度非常慢（如果从一张图片中选取了上千个提议区域，就需要上千次的卷积神经网络的前向传播来执行目标检测，计算量非常大）




Fast R-CNN﻿
目标检测 P1 - 04:49
﻿



R-CNN 每次拿到一张图片都需要抽取特征，如果说一张图片中生成的锚框数量较大，抽取特征的次数也会相应的增加，大大增加了计算量
因此，R-CNN 的主要性能瓶颈在于，对于每个提议区域，卷积神经网络的前向传播是独立的，没有共享计算（这些提议区域通常有重叠，独立的特征提取会导致重复计算）





Faste R-CNN 的改进是：在拿到一张图片之后，首先使用 CNN 对图片进行特征提取（不是对图片中的锚框进行特征提取，而是对整张图片进行特征提取，仅在整张图像上执行卷积神经网络的前向传播），最终会得到一个 7 * 7 或者 14 * 14 的 feature map
抽取完特征之后，再对图片进行锚框的选择（selective search），搜索到原始图片上的锚框之后将其（按照一定的比例）映射到 CNN 的输出上
映射完锚框之后，再使用 RoI pooling 对 CNN 输出的 feature map 上的锚框进行特征抽取，生成固定长度的特征（将 n * m 的矩阵拉伸成为 nm 维的向量），之后再通过一个全连接层（这样就不需要使用SVM一个一个的操作，而是一次性操作了）对每个锚框进行预测：物体的类别和真实的边缘框的偏移
上图中黄色方框的作用就是将原图中生成的锚框变成对应的向量
Fast R-CNN 相对于 R-CNN 更快的原因是：Fast R-CNN 中的 CNN 不再对每个锚框抽取特征，而是对整个图片进行特征的提取（这样做的好处是：不同的锚框之间可能会有重叠的部分，如果对每个锚框都进行特征提取的话，可能会对重叠的区域进行多次重复的特征提取操作），然后再在整张图片的feature中找出原图中锚框对应的特征，最后一起做预测


Fast R-CNN 中的主要计算：






Faster R-CNN﻿
目标检测 P1 - 09:23
﻿

为了精确地检测目标结果，Fast R-CNN 模型通常需要在选择性搜索中生成大量的提议区域
因此，Faster R-CNN 提出将选择性搜索替换为区域提议网络（region proposal network，RPN），模型的其余部分保持不变，从而减少区域的生成数量，并保证目标检测的精度



Faster R-CNN 的改进：使用 RPN 神经网络来替代 selective search 
RoI 的输入是CNN 输出的 feature map 和生成的锚框
RPN 的输入是 CNN 输出的 feature map，输出是一些比较高质量的锚框（可以理解为一个比较小而且比较粗糙的目标检测算法： CNN 的输出进入到 RPN 之后再做一次卷积，然后生成一些锚框（可以是 selective search 或者其他方法来生成初始的锚框），再训练一个二分类问题：预测锚框是否框住了真实的物体以及锚框到真实的边缘框的偏移，最后使用 NMS 进行去重，使得锚框的数量变少）
RPN 的作用是生成大量结果很差的锚框，然后进行预测，最终输出比较好的锚框供后面的网络使用（预测出来的比较好的锚框会进入 RoI pooling，后面的操作与 Fast R-CNN 类似）
通常被称为两阶段的目标检测算法：RPN 做小的目标检测（粗糙），整个网络再做一次大的目标检测（精准）
Faster R-CNN 目前来说是用的比较多的算法，准确率比较高，但是速度比较慢


区域提议网络的计算步骤：


区域提议网络作为Faster R-CNN 模型的一部分，是和整个模型一起训练得到的（Faster R-CNN 的目标函数不仅包括目标检测中的类别和边界框预测，还包括区域提议网络中锚框的二元类别和边界框预测）
作为端到端训练的结果，区域提议网络能够学习到如何生成高质量的提议区域，从而在减少了从数据中学习的提议区域的数量的情况下，仍然保持了目标检测的精度




Mask R-CNN﻿
目标检测 P1 - 13:38
﻿

如果在训练集中还标注了每个目标在图像上的像素级位置，Mask R-CNN 能够有效地利用这些相近地标注信息进一步提升目标检测地精度



Mask R-CNN 是基于 Faster R-CNN 修改而来的，改进在于

假设有每个像素的标号的话，就可以对每个像素做预测（FCN）
将兴趣区域汇聚层替换成了兴趣区域对齐层（RoI pooling -> RoI align），使用双线性插值（bilinear interpolation）保留特征图上的空间信息，进而更适于像素级预测：对于pooling来说，假如有一个3 * 3的区域，需要对它进行2 * 2的RoI pooling操作，那么会进行取整从而切割成为不均匀的四个部分，然后进行 pooling 操作，这样切割成为不均匀的四部分的做法对于目标检测来说没有太大的问题，因为目标检测不是像素级别的，偏移几个像素对结果没有太大的影响。但是对于像素级别的标号来说，会产生极大的误差；RoI align 不管能不能整除，如果不能整除的话，会直接将像素切开，切开后的每一部分是原像素的加权（它的值是原像素的一部分）
兴趣区域对齐层的输出包含了所有与兴趣区域的形状相同的特征图，它们不仅被用于预测每个兴趣区域的类别和边界框，还通过额外的全卷积网络预测目标的像素级位置




模型精度的比较




x 轴表示模型的运行速度，越往右表示模型的速度越快，越往左越慢
y 轴表示 mAP（可以简单认为是边界框的预测精度），越往上表示精度越高
图中圆圈的大小表示内存的使用
Faster RCNN 相对来说精度比较高，但是它在精度提升的同时，样本的处理速度也在变慢（所以只有在对精度要求特别高的场景下会采用 Faster RCNN，但是在工业上使用较少）




总结



R-CNN 是最早、也是最有名的一类基于锚框和 CNN 的目标检测算法（R-CNN 可以认为是使用神经网络来做目标检测工作的奠基工作之一），它对图像选取若干提议区域，使用卷积神经网络对每个提议区域执行前向传播以抽取其特征，然后再用这些特征来预测提议区域的类别和边框
Fast/Faster R-CNN持续提升性能：Fast R-CNN 只对整个图像做卷积神经网络的前向传播，还引入了兴趣区域汇聚层（RoI pooling），从而为具有不同形状的兴趣区域抽取相同形状的特征；Faster R-CNN 将 Fast R-CNN 中使用的选择性搜索替换为参与训练的区域提议网络，这样可以在减少提议区域数量的情况下仍然保持目标检测的精度；Mask R-CNN 在 Faster R-CNN 的基础上引入了一个全卷积网络，从而借助目标的像素级位置进一步提升目标检测的精度
Faster R-CNN 和 Mask R-CNN 是在追求高精度场景下的常用算法（Mask R-CNN 需要有像素级别的标号，所以相对来讲局限性会大一点，在无人车领域使用的比较多）








单发多框检测（SSD）﻿
目标检测 P1 - 21:38
﻿



对每个像素生成多个以它为中心的多个锚框







输入图像之后，首先进入一个基础网络来抽取特征，抽取完特征之后对每个像素生成大量的锚框（每个锚框就是一个样本，然后预测锚框的类别以及到真实边界框的偏移）
SSD 在给定锚框之后直接对锚框进行预测，而不需要做两阶段（为什么 Faster RCNN 需要做两次，而 SSD 只需要做一次？SSD 通过做不同分辨率下的预测来提升最终的效果，越到底层的 feature map，就越大，越往上，feature map 越少，因此底层更加有利于小物体的检测，而上层更有利于大物体的检测）
SSD 不再使用 RPN 网络，而是直接在生成的大量样本（锚框）上做预测，看是否包含目标物体；如果包含目标物体，再预测该样本到真实边缘框的偏移




模型精度




上图中绿色的点表示 SSD
从图中可以看出，SSD 相对于Faster RCNN 来讲速度快很多，但是精度不是太好
SSD 的实现相对来讲比较简单，R-CNN 系列代码的实现非常困难




总结



SSD通过单神经网络来检测模型
以每个像素为中心产生多个锚框
在多个段的输出上进行多尺度的检测（底层检测小物体，上层检测大物体）








YOLO﻿
目标检测 P1 - 30:54
﻿



yolo 也是一个 single-stage 的算法，只有一个单神经网络来做预测
yolo 也需要锚框，这点和 SSD 相同，但是 SSD 是对每个像素点生成多个锚框，所以在绝大部分情况下两个相邻像素的所生成的锚框的重叠率是相当高的，这样就会导致很大的重复计算量。
yolo 的想法是尽量让锚框不重叠：首先将图片均匀地分成 S * S 块，每一块就是一个锚框，每一个锚框预测 B 个边缘框（考虑到一个锚框中可能包含多个物体），所以最终就会产生 S ^ 2 * B 个样本，因此速度会远远快于 SSD
yolo 在后续的版本（V2,V3,V4...）中有持续的改进，但是核心思想没有变，真实的边缘框不会随机的出现，真实的边缘框的比例、大小在每个数据集上的出现是有一定的规律的，在知道有一定的规律的时候就可以使用聚类算法将这个规律找出来（给定一个数据集，先分析数据集中的统计信息，然后找出边缘框出现的规律，这样之后在生成锚框的时候就会有先验知识，从而进一步做出优化）




模型精度




上图中表示 yolo v3 的直线底端表示论文中的原始精度，顶端表示通过改进之后所能达到的最大精度








center net﻿
目标检测 P1 - 39:39
﻿



基于非锚框的目标检测
center net 的优点在于简单
center net 会对每个像素做预测，用 FCN 对每个像素做预测（类似于图像分割中用 FCN 对每个像素标号），预测该像素点是不是真实边缘框的中心点（将目标检测的边缘框换算成基于每个像素的标号，然后对每个像素做预测，就免去了一些锚框相关的操作）








Q&A



1、请问一下，测试数据增强做平均，是结果做平均还是概率做平均？还是看实际情况选择？﻿
QA P2 - 00:00
﻿


2、多模型融合是不是性价比不高？对小样本数据呢？﻿
QA P2 - 00:32
﻿


3、请问 RoI 会不会把图片压变形？这样的话对预测有影响吗？﻿
QA P2 - 02:45
﻿


4、锚框的位置怎么在训练过程中越来越接近目标框？﻿
QA P2 - 03:26
﻿


5、请问在 SSD 中对于密集小目标检测时，即便是第一个 feature map 上的先验框的 stride 映射回原图像时，都远大于小目标之间的距离时（比如文本行框），该怎么设置网络？﻿
QA P2 - 04:14
﻿


6、对于带有方向的 box 预测时，有什么速度快、精度高的网络模型吗？﻿
QA P2 - 06:44
﻿


7、深度学习与统计学习的关系？（如果还有时间，老师帮忙看下原问题，比较长：https://discuss.d2l.ai/t/topic/1744/2）﻿
QA P2 - 07:46
﻿


8、目前这种非锚框实现的有经典论文推荐吗？想去看一下﻿
QA P2 - 08:53
﻿


9、yolo 的锚框实在每个网络的中心进行预测吗？﻿
QA P2 - 08:55
﻿


10、不同尺度的特征图上对锚框进行预测，最后怎么 scale 成原始图像的真实预测框？﻿
QA P2 - 09:15
﻿


11、想问一下对于一个物体进行拍摄视频，然后再进行分类，图片上面类别特征比较小，这种情况用 cnn 进行图片分类比较好，还是直接用目标检测比较好？﻿
QA P2 - 11:08
﻿


12、当下车牌识别使用什么模型或者技术是性能和准确率综合比较好的？﻿
QA P2 - 13:32
﻿


13、最近也看了几个模型的结构，我的理解是卷积、激活函数、池化、全连接等的组合，不知道这样理解对不对，为什么不同的组合会有不同的效果呢，具体和什么有关系？﻿
QA P2 - 14:15
﻿








----end----

其他参考：

1、《动手学深度学习》，课程安排，https://courses.d2l.ai/zh-v2/assets/pdfs/part-2_10.pdf

2、模型精度对比，https://cv.gluon.ai/model_zoo/detection.html

3、《动手学深度学习》，课程安排，https://courses.d2l.ai/zh-v2/assets/pdfs/part-2_11.pdf

4、《动手学深度学习》，课程安排，https://courses.d2l.ai/zh-v2/assets/pdfs/part-2_12.pdf

5、《动手学深度学习》，https://zh-v2.d2l.ai/chapter_computer-vision/rcnn.html 作者：如果我是泡橘子 https://www.bilibili.com/read/cv15651584/?from=readlist&jump_opus=1 出处：bilibili