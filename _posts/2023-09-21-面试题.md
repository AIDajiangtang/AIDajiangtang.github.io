---
published: false
layout: post
title: "0.序"
categories: 我的AI新书
banner:
  video: https://vjs.zencdn.net/v/oceans.mp4
  loop: true
  volume: 0.8
  start_at: 8.5
  image: https://bit.ly/3xTmdUP
  opacity: 0.618
  background: "#000"
  height: "100vh"
  min_height: "38vh"
  heading_style: "font-size: 4.25em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
excerpt: "序"
top: 2

---
https://www.mygreatlearning.com/blog/machine-learning-interview-questions/
https://deeplearning.lipingyang.org/wp-content/uploads/2016/12/41-Key-Machine-Learning-Interview-Questions-with-Answers.pdf



1.背后的原理
2.编程技能
3.行业嗅觉

- 背后的原理
1.偏差-方差权衡
https://zhuanlan.zhihu.com/p/272552385
https://www.cnblogs.com/HuZihu/p/9692796.html


2.ROC曲线的作用



- BAT机器学习1000问
https://zhuanlan.zhihu.com/p/30301789

1.请简要介绍下SVM
支持向量机（Support Vector Machine，简称SVM）是一种监督学习算法，主要用于分类任务，也可以用于回归分析。SVM的核心思想是找到一个超平面（在二维空间中是一条直线，在三维空间中是一个平面，以此类推），这个超平面能够最大化地分隔不同类别的数据点。

SVM的优化目标可以分为两个主要部分：

1. **间隔最大化（Margin Maximization）**：
   - SVM试图找到一个超平面，使得最近的、来自不同类别的数据点（称为支持向量）之间的距离（即间隔）最大化。这个间隔可以被视为模型的“安全边界”，它反映了模型对于未知数据的泛化能力。间隔越大，模型的泛化能力通常越好，因为它对噪声和异常值的鲁棒性更强。

2. **分类错误最小化（Classification Error Minimization）**：
   - 同时，SVM也试图最小化分类错误。这意味着算法希望找到的超平面能够正确分类尽可能多的数据点。在理想情况下，所有数据点都会被正确分类，但实际上可能会有一些数据点位于错误的一侧，这些点被称为支持向量。

SVM的优化问题通常表述为一个凸二次规划问题（Convex Quadratic Programming Problem），其目标函数是间隔的倒数与分类错误的加权和。这个目标函数需要在满足一定约束条件的情况下最小化。在二分类问题中，这些约束条件确保了数据点被正确分类，并且支持向量位于间隔边界上。

数学上，SVM的优化目标可以表示为：

\[
\begin{align*}
& \min_{w, b, \xi} \frac{1}{2} \|w\|^2 + C \sum_{i=1}^{n} \xi_i \\
& \text{subject to} \quad y_i (w \cdot x_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad i = 1, \ldots, n
\end{align*}
\]

其中：
- \( w \) 是超平面的法向量。
- \( b \) 是超平面的偏置项。
- \( \xi_i \) 是松弛变量，用于处理分类错误。
- \( C \) 是正则化参数，用于控制间隔最大化和分类错误最小化之间的权衡。
- \( y_i \) 是数据点的标签（+1或-1）。
- \( x_i \) 是数据点的特征向量。
- \( \cdot \) 表示向量的点积。

在实际应用中，SVM的优化问题通常通过序列最小优化（Sequential Minimal Optimization，SMO）算法或其他二次规划求解器来解决。


2.请简要介绍下tensorflow的计算图
TensorFlow的计算图（Computation Graph）是TensorFlow框架中的核心概念，它是一种用于表示和执行数据流计算的抽象数据结构。计算图由节点（Nodes）和边（Edges）组成，其中节点代表计算操作（如加法、乘法等），而边代表在节点之间传递的数据（即张量，Tensors）。

以下是计算图的一些关键特点：

节点（Operations）：计算图中的每个节点代表一个计算操作，例如加法（tf.add）、卷积（tf.nn.conv2d）等。节点可以接收零个或多个输入张量，并产生一个输出张量。

边（Tensors）：边连接不同的节点，表示数据在节点之间的流动。在TensorFlow中，边是不可变的，一旦数据通过边从一个节点传递到另一个节点，就不能更改。

图的构建：在TensorFlow程序中，首先构建计算图，定义所有需要执行的操作和数据流。这个过程是声明性的，意味着你描述了想要执行的计算，而不是指定如何执行。

图的执行：一旦计算图被构建，TensorFlow会创建一个会话（Session）来执行图。在会话中，可以控制图的执行流程，例如通过指定要执行的节点或者设置断点。

自动微分（Autodiff）：TensorFlow的计算图支持自动微分，这是深度学习中优化模型参数的关键功能。通过反向传播算法，TensorFlow可以自动计算梯度，这对于训练神经网络非常重要。

可扩展性：计算图的设计允许在多个设备（如CPU、GPU、TPU）上并行执行计算，这使得TensorFlow非常适合于大规模数据处理和高性能计算任务。

灵活性：计算图提供了高度的灵活性，允许用户定义复杂的计算结构，并且可以在运行时动态地改变图的结构。

计算图是TensorFlow实现其强大功能的基础，它使得TensorFlow能够高效地处理复杂的数据流计算，特别是在机器学习和深度学习领域。

3.在k-means或kNN，我们常用欧氏距离来计算最近的邻居之间的距离，有时也用曼哈顿距离，请对比下这两种距离的差别。


为什么说LR是参数模型，SVM是非参数模型？
在统计学和机器学习中，参数模型（parametric models）和非参数模型（non-parametric models）是根据模型对数据生成过程的假设来区分的。这两个术语描述了模型对数据分布的灵活性和复杂性。

**参数模型（Parametric Models）**：
- 参数模型是基于一个固定的参数集合来定义的，这些参数完全确定了模型的结构和形式。在参数模型中，模型的复杂度是由参数的数量和类型预先设定的，而不是由数据本身决定。
- 参数模型通常假设数据遵循某个已知的概率分布，例如正态分布、泊松分布等。逻辑回归（Logistic Regression）就是一个典型的参数模型，它假设数据遵循伯努利分布，并且模型的形式（即决策边界）是由有限数量的参数（权重和偏置）决定的。

**非参数模型（Non-parametric Models）**：
- 非参数模型不依赖于数据分布的特定形式，它们通常具有更高的灵活性，可以适应更复杂的数据结构。非参数模型的复杂度不是由参数数量决定的，而是由模型本身的结构和数据的特性共同决定。
- 支持向量机（Support Vector Machine, SVM）是一个非参数模型的例子。SVM通过寻找最优的超平面来分隔数据，这个超平面的位置和形状完全由数据中的支持向量决定，而不是由预先设定的参数数量决定。SVM的决策边界可以是线性的，也可以是非线性的，这取决于数据的分布和支持向量的位置。

总结来说，逻辑回归（LR）被认为是参数模型，因为它假设数据遵循特定的分布（伯努利分布），并且模型的形式由有限数量的参数确定。而SVM被认为是非参数模型，因为它不依赖于数据的特定分布，模型的复杂度和形式由数据本身决定，特别是由支持向量的位置决定。

微软面试题100系列