---
published: false
layout: post
title: "HELM论文精读"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "HELM论文精读"
---


Holistic Evaluation of Language Models
语言模型的全面评估
论文地址：https://arxiv.org/abs/2211.09110


讲解这篇文章的两个理由

1、大部分可能觉得比较大的语言模型离自己比较远，训练一个这类的模型的成本现在基本上在 1000 万人民币以上

这个和造飞机有点类似，造飞机的成本非常高，只有很少的公司会造飞机，但是飞机造出来之后，大家乘坐的概率还是挺高的，因此了解不同飞机之间的性能、舒适性以及安全性等能够更好地帮助自己选择乘坐的机型
同样，做研究或者是做产品的时候也能有助于选择更好的语言模型
2、这篇文章的篇幅比较长，详细介绍了这些语言模型能够应用在自然语言处理的哪些任务上，以及对它做评测时各个评测指标是如何定义的

它是一篇很好的介绍性的文章，甚至可以将它作为一篇综述文章来阅读




省流版

几点发现：

1、InstructGPT 在整体任务上面表现是最好的

2、现在这种开源的模型和闭源的商业模型之间还是有一定的差距的

闭源模型通过用户访问 API 进行收费（闭源的商业模型效果更好也在情理之中，否则就没有必要收费了）
开源的模型也在不断进步，说不定半年之后就能够和现在这些闭源的模型相媲美了
3、在一个模型中，模型通常来说是越大越好

如果在模型之间做比较，如果想在某个领域做得比较好的话，至少需要一个 50B （500 亿参数）的模型。大的模型不管是训练还是部署都会有问题。
4、在用语言模型做各种任务的时候，需要给它一个 prompt ，也就是一个提示，但是所有的语言模型对提示的样式非常敏感





标题

Holistic Evaluation of Language Models
语言模型的评估
Holistic：全面的、整体的。通常文章使用 comprehensive








作者


作者都是来自于斯坦福的作者
斯坦福还成立了一个关于 foundation 模型的研究机构：CRFM
共同一作有三个人：

Percy Liang 是斯坦福的副教授
﻿
04:44
Percy Liang
﻿
后面的两位是他的学生
这里的一作不是按照姓进行排序的，这里应该是有先有顺序的，因此真正的一作就是 Percy Liang 
这种老板做第一作者的文章其实并不多见，有可能是整篇文章的框架以及写作都是由老板完成的。这种评测文章将老板放在前面的话多少能够增加一些整个论文的权威性，不管是评测还是综述，虽然是一种比较客观的论文类型，但其实里面还是有很多的主观性，所以作者能够对文章的置信度产生比较大的影响








摘要

语言模型现在已经成为所有主要语言技术的基石，但是它的能力、局限性以及风险并没有被完全的理解

这篇文章的贡献：

1、它将潜在的应用场景以及评估手段进行了分类，并选取了一小部分做了详细的评测

2、它做了 7 个评估的指标，包括精度、校准、稳健性、公平性、偏差、有毒性和效率，另外还做了 16 个核心场景的评测

之前的文章主要是关于精度和有效性，对于其它的并不是那么关心，这篇文章将每一个尺度都进行了评估
3、它评估了 30 个语言模型，市面上能够找到的模型基本上都找了，然后在 42 个场景上面做了评估，相对来讲比较全面

这篇文章和其它的工作相比，其它工作可能只覆盖了 17.9% 的场景，这篇文章覆盖了 96%

对于一篇评测文章，如果说自己比其它工作做的好，通常是说自己做的工作更大、更全面，比如评测更多的产品，以及对每个产品评测的内容更全面。假设评测是公平的，如果一个评测没有客观性和公平性，基本上就没有什么参考价值了
任何的评测都是有时效性的，因此这篇文章发表之后基本上只能够代表当时的模型现状，文章发表的同时也标志着这篇文章的过时，因为会有新的模型和新的应用场景，里面的结论过了一段时间之后可能就不成立了
看这篇文章的目的主要是要去了解作者是如何做评测的，以及评测了哪些方面，使得在之后读到相关文章的时候能够判断出来文章作者在对自己的模型做实验的时候，他的评估是不是足够全面（将他的评测框架带到这篇文章中看他覆盖了哪些应用场景）
此外，如果未来的工作需要基于某一个语言模型，也可以根据本文所提到的方法自己进行评测








目录

因为这篇文章篇幅比较长，所以这里放了一个目录
1、导言

2、背景知识

3、核心的应用场景

主要是对 NLP 任务的介绍，比如 QA 、摘要、
4、评估指标

精度
公平性
5、对于一个语言模型需要评估哪些方面

对语言的建模
对知识的抽取
推理
如果训练数据中存在版权数据的话，会不会将这些版权数据原封不动地返回
语言模型是不是一本正经地说假话
偏见
有毒性
6、选取的模型

7、实验设置

对于一个语言模型，就是预测下一个词，但是对于不同的任务，会有不同的要求。所以给定一个语言模型，如何让它完成不同的任务
本文所使用的方法主要是基于 prompt ，最简单、最灵活，但是效果不一定最好（这也是这篇文章的一点局限性）
剩下的主要讲了一些实验以及局限性，后面还有一个很详细的附录（100-158）









一、导言


首先介绍了什么是语言模型，语言模型就是给定一些文字，然后补全剩下的文字

对于输入到语言模型的文字，作者把它叫做 prompt （如果想让语言模型完成什么任务的时候，可以将这个任务写成一段话，然后让语言模型来补全剩下的内容）
prompt 如何设计既能反映任务，又能让语言模型能够理解，这当中就有很多的艺术性了
语言模型输出的文字就是语言模型生成的答案


图 2 讲述了这篇文章和之前的文章的区别


﻿
12:06
区别
﻿

之前的文章在做评估的时候，都是拿一些数据集然后进行评测
这篇文章中，作者对数据集进行了归纳总结，这样就能够了解自己在评估数据集的时候覆盖面是什么样的








图 3 展示了这篇文章相比其他工作好在什么地方


﻿
13:19
本文的优越性
﻿

别的工作都是在每个数据集上比较一些特定的指标
本文在不同的数据集上对比了 7 个不同的指标








图 4 


﻿
13:42
图4
﻿

图中每一列表示一个语言模型，每一行表示一个评估的数据集
前面的工作对于每一个模型可能只是评测了一些，本文将填补了这里面的空白，把所有的模型在所有的数据集上做了评估




作者的发现









二、背景知识









三、核心的应用场景

图 8 


作者将应用场景分成了三块：

1、任务

具体来说可以是 QA 、摘要生成、情感分析或者是信息检索
2、领域

可以分成三个因素：

什么样的文本。维基百科的文本？电影的评论？新闻？还是社交媒体类的文字？
文字是谁生成的（文字都是由人类生成的，这些人是谁，未来文字可能是由语言模型生成的，这也是未来要考虑的问题）。网络用户？性别？人种？
数据生成的时间（年份）
3、语言

目前来说英语和中文是两大类语言
所以，对任何的应用场景都可以拆分成为这三大块，其中领域也能够分成三小块

﻿
16:12
to be continue
﻿





表 1 展示了训练任务从哪里来的以及这些任务的覆盖面


任务来自于会议里面的

在提交会议文章的时候，需要标记文章所做的 track 中的任务
于是作者将 ACL 中的任务全部抽取出来，然后进行了归类
作者也说，由于最近发展比较快，就算是去年的学术会议的任务也不一定能够覆盖最新的

OpenAI 在官网（https://platform.openai.com/examples/）上列举了很多任务

﻿
16:46
OpenAI 官网样例
﻿


其实很多任务在学术会议中是没有标记出来的，这些任务可能相对来说比较小，或者说可能是一些比较新的任务

对于这篇文章来讲，不可能去评估所有这些比较新的小众的任务，还是需要选择一些有数据集的比较成熟的任务，否则工程量比较大





作者在领域方面详细讲述了

什么是 what 、when 和 who 
文本是在哪里生成的？怎样生成的？以及为什么要生成这些文本？




在语言上，目前来讲最大的两个语言是中文和英文，这篇文章主要关注的还是英文





作者说他只能选一些来做评估，然后列出了具体选择了哪些任务来做评估，几个比较重要的任务：

1、QA（问答）

在日常生活中，问答是用的最多的一种交流方式

通常会将问题分成两块：

开放性问题：给定一段话（或者不给定一段话，直接抛出一个问题），让模型给出正确的答案
关闭式的问题（选择题）：
﻿
19:38
to be continue
﻿








----to be continued---- 作者：如果我是泡橘子 https://www.bilibili.com/read/cv21667268/?from=readlist&jump_opus=1 出处：bilibili