---
published: false
layout: post
title: "预告"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "预告"
---


感知机




人工智能最早的模型
x ，w 都是向量，b 是一个标量
<w , x>：w 和 x 做内积
感知机其实就是一个二分类问题：输入大于0就输出1，否则输出0





和线性回归的不同点在于线性回归输出的是一个实数而感知机输出的是一个离散的类
和softmax的区别是，在有n个类的情况下，他会输出n个元素，所以可以是一个多分类的问题，而这里只输出一个元素，最多只能做一个二分类问题




训练感知机




预测值和实际值不符的话（异号）会导致他们的乘积小于等于零，从而更新权重




收敛定理






收敛定理确定停止的条件
p大于等于0




感知机不能拟合异或函数




无法使用一条直线将图上的四个点分成两类




总结












多层感知机








异或问题




组合两个函数，一层变成了多层




单隐藏层




输入层的大小是固定的，输出层的大小等于类别的数量，唯一可以设置的是隐藏层的大小




单分类问题




为什么需要非线性激活函数？线性的激活函数或导致最终输出还是一个线性函数，就等价于一个单层的感知机了




激活函数



sigmoid激活函数




将 x 的值投影到一个0和1的开区间中
sigmoid实际上是阶跃函数的温和版


tanh激活函数




和sigmoid很像，区别在于它是将输入投影到-1到1的区间内
-2是为了方便求导




ReLU激活函数




最常用
不用做指数运算




多类分类




softmax就是将所有的输入映射到0和1的区间之内，并且所有输出的值加起来等于1，从而转变成概率



和单分类的区别在于最后的输出做了一个softmax操作




多隐藏层




超参数变多了




总结










多层感知机的代码实现









----to be continued---- 作者：如果我是泡橘子 https://www.bilibili.com/read/cv14228849/?from=readlist&jump_opus=1 出处：bilibili