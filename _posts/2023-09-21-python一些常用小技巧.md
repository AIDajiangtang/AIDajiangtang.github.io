---
published: false
layout: post
title: "0.序"
categories: python中的一些常用小技巧
banner:
  video: https://vjs.zencdn.net/v/oceans.mp4
  loop: true
  volume: 0.8
  start_at: 8.5
  image: https://bit.ly/3xTmdUP
  opacity: 0.618
  background: "#000"
  height: "100vh"
  min_height: "38vh"
  heading_style: "font-size: 4.25em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
excerpt: "序"
top: 2

---

**1**
使用numpy中的concatenate函数对NLP中同一个batch的文本进行padding或者截断
padded_sent = np.concatenate([sent[:seq_len], [pad_id] * (seq_len - len(sent))]).astype('int32')
下面句子创建包含seq_len - len(sent)个pad_id元素的列表
[pad_id] * (seq_len - len(sent))


**numpy 存储图像时第一个维度是高度（图像行数rows），第二个维度是宽度（图像列数cols）**

**OPenCV读取彩色图像时，通道顺序是B，G，R**
OpenCV在读取彩色图像的时候,通道顺序默认为BGR,这和我们常见的RGB顺序是不同的。

具体来说,对于一个3通道的彩色图像,在OpenCV中表示为一个三维的numpy数组,其中:

第一维(axis=0):图像高度
第二维(axis=1):图像宽度
第三维(axis=2):颜色通道,顺序为BGR

import cv2
img = cv2.imread('color_img.jpg') 

print(img.shape) # 比如 (480, 640, 3)  

# 访问某个像素的B通道值
b = img[100, 200, 0] 

# 访问G通道和R通道 
g = img[100, 200, 1]
r = img[100, 200, 2]



**通过Numpy和matplotlib绘制函数曲线的代码例子**

```python

import numpy as np
import matplotlib.pyplot as plt

def gradient_descent(f, df, x0, learning_rate, num_iterations):
    x = x0
    x_history = [x]
    
    for _ in range(num_iterations):
        gradient = df(x)
        x -= learning_rate * gradient
        x_history.append(x)
    
    return np.array(x_history)

# 定义函数f(x)
def f(x):
    return x**2 + 10*np.sin(x)

# 定义函数f(x)的导数df(x)
def df(x):
    return 2*x + 10*np.cos(x)

# 设置初始参数值和学习率
x0 = -5
learning_rate = 0.1
num_iterations = 100

# 运行梯度下降算法
x_history = gradient_descent(f, df, x0, learning_rate, num_iterations)

# 绘制函数曲线和梯度下降路径
x_range = np.linspace(-10, 10, 100)
plt.plot(x_range, f(x_range), label='f(x)')
plt.scatter(x_history, f(np.array(x_history)), c='red', label='Gradient Descent')
plt.legend()
plt.xlabel('x')
plt.ylabel('f(x)')
plt.title('Gradient Descent')
plt.show()

```

**通过Numpy和matplotlib绘制具有两个自变量函数的曲面的代码例子**

```python

import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

def f(x, y):
    return x**2 + y**2

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')

x = y = np.arange(-3, 3, 0.1)
X, Y = np.meshgrid(x, y)
zs = f(X, Y)

ax.plot_surface(X, Y, zs)

ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')

plt.show()

```


**SGD**

```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# 定义损失函数
def loss_function(x, y):
    return (x - 1) ** 2 + (y - 2) ** 2

# 定义梯度函数
def gradient(x, y):
    return np.array([2 * (x - 1), 2 * (y - 2)])

# 生成数据
x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
X, Y = np.meshgrid(x, y)
Z = loss_function(X, Y)

# 绘制3D图形
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(X, Y, Z, cmap='viridis')

# SGD迭代更新参数
eta = 0.1
theta = np.array([0, 0])
num_iterations = 100
for i in range(num_iterations):
    gradient_value = gradient(theta[0], theta[1])
    theta = theta - eta * gradient_value
    ax.scatter(theta[0], theta[1], loss_function(theta[0], theta[1]), color='red')

plt.show()

```

**牛顿法**
```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# 定义目标函数
def objective_function(x, y):
    return x**2 + 2*y**2

# 定义梯度函数
def gradient(x, y):
    return np.array([2*x, 4*y])

# 定义黑塞矩阵
def hessian_matrix():
    return np.array([[2, 0], [0, 4]])

# 生成数据
x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
X, Y = np.meshgrid(x, y)
Z = objective_function(X, Y)

# 绘制3D图形
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(X, Y, Z, cmap='viridis')

# 牛顿法迭代更新参数
theta = np.array([0, 0])
num_iterations = 10
for i in range(num_iterations):
    gradient_value = gradient(theta[0], theta[1])
    hessian_inverse = np.linalg.inv(hessian_matrix())
    theta = theta - np.dot(hessian_inverse, gradient_value)
    ax.scatter(theta[0], theta[1], objective_function(theta[0], theta[1]), color='red')

plt.show()

```

