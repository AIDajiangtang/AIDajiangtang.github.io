---
published: false
layout: post
title: "预告"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "预告"
---


LeNet



由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名）
目的是用来做手写数字识别


知名度最高的就是MNIST数据集（LeNet模型提出时所附带的数据集）


虽然只有5w个数据，但是在当时来讲还是一个很大的数据集，当时的内存只有几M
图像的大小是28*28，单通道灰度图




LeNet架构


每个卷积块中的基本单元是一个卷积层、一个sigmoid激活函数和平均汇聚层（虽然ReLU和最大汇聚层更有效，但它们在20世纪90年代还没有出现）
每个卷积层使用5*5卷积核和一个sigmoid激活函数，这些层将输入映射到多个二维特征输出，通常同时增加通道的数量
每个2×2池化操作通过空间下采样将维数减少4倍


实现流程

模型的输入是32*32大小的image（MNIST数据集的图片大小是28*28，这里模型的输入为什么和数据集中图片的大小不一致？因为在卷积块中每一层的特征相比上一层的高度和宽度都减小了，所以对输入的图片进行了两个像素的padding处理，来补偿5*5卷积核导致的特征减少）----nn.Conv2d(1,6,kernel_size=5,padding=2),nn.sigmoid()，这里的padding等于2指的是上下左右各填充2行，所以28*28就变成了（28+2+2）*（28+2+2），sigmoid（）函数用于增加模型的非线性
接下来放入一个5*5的卷积层中，输出是28*28*6，这里由于前一步进行了填充，所以输出的大小是28*28，与输入图片的尺寸相同
再用一个2*2的pooling层，使上一步的输出由28*28*6变成了14*14*6
然后又使用了一个5*5的卷积层，使上一步的输出由14*14*6变成了10*10*16，由于卷积之前没有进行padding，所以卷积之后的特征图尺寸的高度和宽度都减少了4个像素
再用同样2*2的pooling层，使上一步的输出由10*10*16变成了5*5*16
接着将上一步的输出展平成为一个向量，然后输入进一个120的全连接层，再将结果输入进一个84的全连接层----nn.Flatten()
最后通过一个Gauss（高斯）层，也可以认为是一个全连接层，得到一个10层的输出--0到9的10个数字的概率（输出层的10维对应最后输出的结果的数量）
模型共有两个卷积层、两个全连接层、两个池化层和一个输出层




总结

Lenet是是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注
先用卷积层来学习图片的空间信息，通过池化层降低图片的敏感度
然后使用全连接层来转换到类别空间，得到10类
两个卷积层再加一个多层感知机，最终得到从图片到类别的映射




Q&A

池化和卷积是不是更适合图像这类型的数据，而对于时序性的数据（做分类）是不是不适用这类数据？﻿
QA P3 - 00:11
﻿


LeNet第二个卷积层通道数增加到了16，这意味着信息量被放大了吗？或者说信息在通道中是怎样流通的？﻿
QA P3 - 01:09
﻿


为什么用view而不用reshape呢？﻿
QA P3 - 02:56
﻿


选择深度学习模型是用mlp还是cnn，是一种试的心态来选择还是说应该先从理论上推导，如果行得通再选择用哪一个模型？﻿
QA P3 - 04:19
﻿


Conv2d 6 -> 16，16个通道是怎么取前面6各通道的信息的（每个都取还是按一定组合取的）？ ﻿
QA P3 - 05:43
﻿


输出通道增多，这些增加的信息是些什么？可以理解是随机扩充的图片信息么？﻿
QA P3 - 06:14
﻿


卷积层输出通道数的选择有什么理由吗？比如，刚才讲的输出通道数6和16.可以改成5和15吗？﻿
QA P3 - 07:37
﻿


像这些经典的网络，有没有必要把每层的参数，像channels，strides，padding这些都背下来？（面试可能会问）﻿
QA P3 - 12:15
﻿


池化层一般用max还是avg，用max的话会不会损失很多信息？﻿
QA P3 - 13:49
﻿


LeNet当时是用什么语言实现的呢？LeNet的卷积层是不是没加bias？﻿
QA P3 - 14:32
﻿


神经网络的准确率一般到多少算是比较好的？﻿
QA P3 - 16:56
﻿


老师，为什么用了一层卷积，就从1个通道变成了6个通道？是每个通道用了不同的卷积核吗？﻿
QA P3 - 19:00
﻿


想请教autogloun是否能做时序任务，昨天试了下表格预测模块做时序任务，结果不理想，是我没操作对吗？﻿
QA P3 - 19:53
﻿


能介绍一下Conv2d和Conv3d以及MaxPool2d和3d的差别，以及各自适用的场景吗？﻿
QA P3 - 21:08
﻿


课程网站有一个练习是将sigmoid替换成relu，四个sigmoid全替换以后模型基本不收敛，有什么原因吗？一般用relu应该比sigmoid更容易收敛？﻿
QA P3 - 22:28
﻿


图像识别出来的特征（颜色、形状）可以打印出来吗，或者怎么去寻找网络到底学习了什么？﻿
QA P3 - 23:30
﻿


在跑得动的情况下，中间计算层的输出通道尽量调大么？﻿
QA P3 - 26:05
﻿


老师，想问一下目前的卷积神经网络或其他深度学习网络是不是都需要较多的数据，如果训练数据体量很小是否不适合用深度学习？是否有无监督/或小训练集的深度学习？﻿
QA P3 - 26:41
﻿


请问训练后的权重能做visualization进行分析吗？﻿
QA P3 - 27:34
﻿


卷积网络等网络是把非结构化数据转换成结构化数据然后来解决问题，这个想法可以通用在深度学习领域吗？﻿
QA P3 - 28:20
﻿








----end----

其它参考：

1、《动手学深度学习》，https://zh-v2.d2l.ai/chapter_convolutional-neural-networks/lenet.html#id2 作者：如果我是泡橘子 https://www.bilibili.com/read/cv15256705/?from=readlist&jump_opus=1 出处：bilibili