---
published: true
layout: post
title: "一起学AI 7.回归分析"
categories: 一起学AI

banner:
  video: https://vjs.zencdn.net/v/oceans.mp4
  loop: true
  volume: 0.1
  start_at: 8.5
  image: https://bit.ly/3xTmdUP
  opacity: 0.618
  background: "#000"
  height: "100vh"
  min_height: "38vh"
  heading_style: "font-size: 4.25em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
excerpt: "一起学AI 7.回归分析"
top: 4
---


**回归分析的概念以及发展史**
回归分析是一种统计学方法，用于研究一个或多个自变量和因变量之间的关系。回归分析可以用来描述变量之间的关联程度，建立变量之间的数学模型，以及进行变量的预测和控制。

回归分析的概念最早是由英国生物学家高尔顿（Galton）提出的，他在1886年发表了一篇论文，研究了父母的身高和子女的身高之间的关系。他发现，子女的身高往往倾向于接近人类的平均身高，这种现象被称为“回归”1。高尔顿的回归分析主要是用来研究遗传现象的，他没有引入控制变量的概念，也没有区分相关和因果的关系。

回归分析的发展受到了许多统计学家的贡献，其中最重要的是皮尔逊（Pearson）和尤勒（Yule）。皮尔逊是高尔顿的学生，他在1900年提出了卡方检验和卡方分布的概念，发展了回归分析和相关分析的理论和方法。他还创办了《生物统计学》（Biometrika）杂志，推动了生物统计学和社会统计学的发展2。尤勒是皮尔逊的学生，他在1899年发表了一篇论文，研究了英国济贫法对贫困率的影响。他在回归分析中引入了控制变量的概念，试图找出变量之间的因果关系，而不仅仅是相关关系3。尤勒的回归分析可以说是社会科学中政策效应因果识别的先驱。

回归分析的类型很多，根据自变量和因变量的数量和性质，可以分为简单回归分析和多元回归分析，线性回归分析和非线性回归分析，参数回归分析和非参数回归分析等。回归分析的应用也很广泛，涉及到自然科学，社会科学，工程技术，经济管理等各个领域。回归分析是一种强大的统计学工具，可以帮助我们揭示变量之间的规律，解决实际问题，提高决策水平。


**回归分析与机器学习中的线性回归和逻辑回归有什么区别？**

回归分析是一种统计学方法，用于研究一个或多个自变量和因变量之间的关系。线性回归和逻辑回归是回归分析的两种常见类型，它们在机器学习中也有广泛的应用。线性回归和逻辑回归的主要区别如下：

线性回归要求因变量是连续性数值变量，逻辑回归要求因变量是分类型变量（如二分类或多分类）1。
线性回归假设因变量和自变量之间是线性关系，逻辑回归不要求自变量和因变量呈线性关系，而是通过一个对数几率函数（logit function）将线性模型转换为非线性模型2。
线性回归的目标是找到一条直线，使得样本点和直线的欧氏距离之和最小，这通常使用最小二乘法来实现。逻辑回归的目标是找到一个概率函数，使得样本点的对数似然函数最大，这通常使用梯度下降法或牛顿法来实现3。
线性回归的结果是一个具体的数值，逻辑回归的结果是一个概率值，通常需要设定一个阈值来判断类别4。

