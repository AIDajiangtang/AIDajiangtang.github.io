---
published: true
layout: post
title: "一起学AI 4-提升AI开发效率的抽象思维"
categories: 一起学AI

banner:
  video: https://vjs.zencdn.net/v/oceans.mp4
  loop: true
  volume: 0.1
  start_at: 8.5
  image: https://bit.ly/3xTmdUP
  opacity: 0.618
  background: "#000"
  height: "100vh"
  min_height: "38vh"
  heading_style: "font-size: 4.25em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
excerpt: "一起学AI 4-提升AI开发效率的抽象思维"
top: 5
---

在正式开始之前，有必要先了解一下“抽象”的概念。

抽象，简单来说，就是把一些具体的、复杂的、细节的东西，用一些简单的、通用的、本质的东西来表示。**抽象的目的，就是为了减少复杂度，提高效率，增强表达力，方便理解和沟通**。

我们身边到处都是抽象的应用，无论是艺术、文学、商业，还是数据、编程、AI，都离不开抽象思维的应用。

艺术上的抽象派不描述复杂的自然世界，而是通过简单的形状、颜色、线条等元素来表达艺术家的主观感受或思想。

![alt]({{ "assets/images/new book/4/abstract_paint.jpeg" | relative_url }})

我国古代诗人通过寥寥数语就能描绘出一个时代的风貌。


![alt]({{ "assets/images/new book/4/poem.jpg" | relative_url }})

无需详尽了解员工和产品细节,仅通过公司的战略就能掌握其业务本质。

![alt]({{ "assets/images/new book/4/Corporate-Strategy.jpg" | relative_url }})

从原始数据中提取知识,再由知识做出决策,这一过程也是一种抽象。

![alt]({{ "assets/images/new book/4/DIKW_Pyramid.png" | relative_url }})


回归AI这一主题。教会机器从数据中学习经验并做出决策，是AI最根本的功能。而AI系统对数据的处理到最终决策，都离不开计算机软硬件的适配与协作。

让我们先来看一下，计算机是如何通过不同层次的抽象，最终将人类的决策转化为CPU可识别执行的二进制机器码的。

## 打孔技术

打孔卡是计算机发展早期使用的一种程序输入设备。最初由赫尔曼·霍利特发明，它是由纸板或纸卡制作的卡片，卡片上有多列可以打孔的槽。程序员可以通过打孔编码在卡片上输入计算机程序。

![alt]({{ "assets/images/new book/4/punch-card.png" | relative_url }})

存储容量小是打孔卡致命的缺点，如果用打孔卡存储一个贪吃蛇程序，就会像拉着一车金圆券去买面包一样。

![alt]({{ "assets/images/new book/4/punch-cards.png" | relative_url }})

最终，在20世纪60年代开始被磁带技术取代，直到现在使用的机械磁盘或者固态硬盘。

## 计算机软件抽象层次

很庆幸我们没有生活在打孔卡那个年代，但今天的幸福也是建立在一代又一代计算机科学家、工程师不懈努力的基础之上。这个努力的过程也是计算机的抽象过程，随着抽象程度的提升，开发效率也在不断提升。

![软件抽象层次]({{ "assets/images/new book/4/softwareablevel.jpg" | relative_url }})

由上图可知，编译器实现了从二进制码到汇编语言,再到高级语言等更高层次抽象迈进。

![alt]({{ "assets/images/new book/4/C++ Java Python.png" | relative_url }})

面向更高级语言的解释器(Interpreter),则是实现抽象化的另一种有效工具。

![计算机抽象层次]({{ "assets/images/new book/4/hardware-abstraction.png" | relative_url }})

高级编程语言实现了对CPU指令集和CPU寄存器的抽象封装；在编程语言的基础上，操作系统又实现了对进程，外设的抽象封装。

针对不同领域也在持续进行着域专用库和基础组件的开发。例如，为简化数值计算与线性代数，出现了BLAS、LAPACK、Eigen、MATLAB等工具库。对于网络和分布式编程的难点，则由libcurl、Boost.Asio、gRPC、Netty等框架进行了封装，降低了开发的门槛与复杂度。

在基础组件的基础上，针对不同行业，例如，医疗、金融、生物化学也有专门的框架和工具，以实现业务抽象。

抽象，从设计模式的角度来看,就是通过将通用技术细节下沉,让业务逻辑上浮，从而提高各组件间的解耦性。

![OSI]({{ "assets/images/new book/4/OSI.png" | relative_url }})


## AI中的抽象层次

人工智能是立足于计算机科学基础之上的前沿技术，因此构建AI系统同样需要抽象化的方法论支撑。

同时AI又是多学科交叉的应用与探索，如此，AI比传统软件系统需要面对更加复杂的问题，对抽象化的依赖也更加紧迫。

![OSI]({{ "assets/images/new book/4/aiab.png" | relative_url }})

让我们自底向上看去。

### 并行计算库

如上图所示，AI与普通程序都需要运行在硬件芯片上，但是AI的训练和推理都需要大量的计算，相比于CPU，拥有并行计算能力的GPU更为常用。

如何高效控制并发计算GPU硬件资源，NVIDIA提供了CUDA这个并行计算平台和编程模型。它针对GPU的架构特点,对其指令集和底层操作进行了抽象封装，让开发者能以更高层次的方式使用GPU的并行计算能力，而不需要直接控制硬件。

### 机器学习框架

如果你不想去调用复杂CUDA函数库，也不擅长线性代数，更不想为如何实现优化算法所烦恼，那机器学习框架是你最好的选择。

机器学习框架对底层数学原理进行了抽象封装。

![机器学习框架]({{ "assets/images/new book/4/allmlframeworks.png" | relative_url }})

![受欢迎程度]({{ "assets/images/new book/4/trends.png" | relative_url }})

除了TensorFlow和PyTorch，scikit-learn作为经典的传统机器学习python库也广泛使用。国内的一些框架也具有竞争力，例如百度的PaddlePaddle，还有华为的MindSpore框架，都被业界视为TensorFlow和PyTorch的有力竞争者。

![大厂AI框架]({{ "assets/images/new book/4/AI framework foren.png" | relative_url }})

上图为各大厂构建的AI生态，所谓大厂开发，必是精品，大厂推出的框架和平台，通常在技术实现和生态建设上更加领先。除了有强大的公司研发实力支持,同时也拥有广泛活跃的开发者社区。

![支持的编程语言]({{ "assets/images/new book/4/language.png" | relative_url }})

为适应不同开发者和运行环境的需求，主流框架通常会支持多种编程语言，如Python、Java、C++等接口的开发。

有了框架，接下来你就可以按照下面流程进行开发了。


![AI开发流程图]({{ "assets/images/new book/4/liuchengtu.png" | relative_url }})

![AI开发流程图]({{ "assets/images/new book/4/allinone.png" | relative_url }})


### 云服务

然而，如果自己没有GPU或高配置服务器，想Training复杂的AI模型该怎么办?这时可以考虑使用云服务，在云服务器上搭建开发环境，开发者可以通过网页远程连接服务器，获得临时的算力支持。

![云服务]({{ "assets/images/new book/4/cloud.png" | relative_url }})


现在这种基础设施即服务的提供越来越成熟，知名的有阿里云、腾讯云、华为云、AWS、Azure等。

### 在线AI平台

如果不想花钱租云服务器，怎么办？这里说一下我个人的经历。

在第一篇文章中,我提到自己是从2019年开始接触AI。这一时间点需要更正到2017年。当时对于初学者来说，第一步肯定就是配置一个主流的AI开发框架。我记得Google当时最流行的TensorFlow框架就是新人的不二之选。然而在我尝试安装TensorFlow时，因为种种依赖与环境问题,终告失败收场。这便应验了那句话——还未开始,就已结束。

直到2019年无意间发现百度的在线平台：AI Studio。

所谓的AI在线平台，就是比云服务器更进一步，你不需要安装任何软件。GPU硬件，驱动，AI框架，以及很多第三方库在服务端已经准备好了，只要有浏览器能上网就行，每个人都有免费的使用额度。

目前为止，我最常用的两个AI在线平台有：AI Studio和谷歌的Colab。

https://aistudio.baidu.com/projectoverview/public
https://colab.research.google.com/?utm_source=scs-index

当然，有的人可能出于数据安全角度，就想在本地安装训练环境，这个对于现在来说也要比当初要容易很多。

你可以安装Anaconda，也就是集成了很多第三方Python库的集成开发环境。

如果你了解容器，很多AI框架也提供了镜像，拉取下来直接用就可以了。

## 提升AI开发效率的工具

讲完了抽象，接下来再给大家介绍一些能够提升AI开发效率的工具。

### 大模型工具

![大模型]({{ "assets/images/new book/4/LLM.png" | relative_url }})

大语言模型已经彻底改变了我们工作的方式，能很大程度上提升开发效率，用AI开发AI也是一种很有意思的手段，你可以用它帮你生成训练、推理代码，让它帮你分析数据，让它帮你评估模型结果等等。

在LLM中也存在着抽象的概念，Foundation Models就是在大规模语料上进行无监督训练得到的，它本质上学习的是语言模型，但这个语言模型还无法完成聊天、总结等具体任务，在FMs基础上进行有监督的微调才能得到像ChatGPT这样的大语言模型。

如何定制自己的大语言模型？也会分为不同的层级。

对于一些大公司，有钱，有技术，就可以从零开始，OPenAI的GPT，Google的Gemini，Anthropic的Claude，Meta的LLaMA就是这样的例子。

这里要特殊说一下Meta，因为目前所有大模型中，只有LLaMA是开源的，但这并不是其本意，因为Meta前几年一直深陷于元宇宙而无暇顾及大模型，后来有所觉悟，为了不被彻底踢出局，所幸将大模型开源，一副“我赚不到钱，大家都别赚钱”的心态。

而这些闭源的大模型厂家，要么发布付费的PlayGround，要么通过付费API供大家调用，这就给一些中小公司提供了商机，套壳一词也就由此而来。

OPenAI提供的API不仅能直接调用发布的大模型，而且还能支持上传数据训练自定义模型。

对于个人用户，要么选择调用API，要么直接使用免费的软件，这里给大家推荐两款：Hayo和Windows自带的Copilot。

**Hayo：**
项目在线网址：https://www.hayo.com
​
或者关注微信公众号：人工智能大讲堂，后台回复hayo获取软件下载链接。

### 模型可视化工具

深度学习的可解释性差一直被人诟病，可视化工具则是一种窥探内部工作的必要工具。

CNN解释器在线演示
https://poloclub.github.io/cnn-explainer/
源码
https://github.com/poloclub/cnn-explainer
论文
https://arxiv.org/abs/2004.1500

除此之外，还有一些非常好的资源，例如，kaggle，通过实战检验原理，Github，存储海量代码资源。

https://www.kaggle.com/
https://github.com/

## 总结：

学会抽象思维，让学习变得更容易，让生活变得更简单，让人生变得更精彩。

**下节预告：**

到此，方法论已经讲完了，接下来将进入具体的细节，让计算机帮人类做事的第一步就是数字化，下一篇文章我们将了解不同的数字化形式和方法。






