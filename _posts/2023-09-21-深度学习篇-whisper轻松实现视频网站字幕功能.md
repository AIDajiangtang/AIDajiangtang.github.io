---
published: false
layout: post
title: "whisper轻松实现视频网站字幕功能"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "whisper轻松实现视频网站字幕功能"
---

OpenAI ChatGPT增加了语音功能
哔哩哔哩和油管上字幕功能
语音翻译

这一切背后离不开语音识别。


**语音识别的发展史**
20世纪50-60年代,规则方法阶段。依靠语言学专家制定各种语音识别规则。准确率极低。
20世纪70-80年代,模式匹配阶段。使用预设的词汇模板,通过模式匹配的方式识别语音。鲁棒性差。
20世纪90年代,统计建模阶段。使用高斯混合模型等统计模型,结合语音特征参数进行识别。效果有所提高。
21世纪早期,深度学习阶段。采用深度神经网络完成端到端的语音识别任务。大幅度提高了识别准确率。
当前阶段,迁移学习和预训练模型阶段。在大规模数据集上预训练语音识别模型,然后迁移应用于特定领域,进一步提高效果。


基于深度学习的语音识别技术：whisper


**whisper将源语言翻译成目标语言时，是端到端的方式还是先识别源语言，再将源语言翻译成目标语言？**

根据 OpenAI 公开的信息,whisper 使用端到端的方法进行语音翻译,没有明确的语音识别和文本翻译两个独立步骤。

具体来说,whisper 利用了一个统一的序列到序列(sequence-to-sequence)模型,输入是源语音,输出是目标语言文本。该模型通过在大量语音翻译数据集上进行端到端训练,学习将源语音直接映射到目标语言翻译结果。

这种方法的优点是可以让模型充分利用语音信号中的语义、语法等上下文信息,进行更准确的语言理解和翻译。相比之下,传统方法需要先将语音识别成文本,再进行翻译,存在信息损失和错误累积的问题。

所以简单来说,whisper 是一种直接端到端的语音翻译方法,可以避免传统流水线方法中的一些问题,实现更好的翻译质量。




**Whisper是如何训练编码器和解码器的？**
根据OpenAI公开的信息,Whisper使用了编码器-解码器(Encoder-Decoder)架构的序列到序列(Seq2Seq)模型进行端到端训练。

具体来说,编码器和解码器的训练过程如下:

编码器:该模块会直接在原始语音信号上进行训练,以学习提取语音特征并生成语音表征。采用了Conformer架构,包含多层卷积和自注意力机制。
解码器:使用了仅包含自注意力机制的Transformer架构。它在词嵌入和编码器输出的条件下,进行目标语言句子的生成。
通过Encoder和Decoder间插入连接层,来传递语音表征特征。
利用机器翻译大规模数据集,进行Encoder和Decoder的联合训练,实现语音信号直接到文本翻译的端到端映射,优化整体模型。
这样的设计允许Encoder学习语音表示,Decoder专注文本生成,通过联合训练形成了一个语音端到端的seq2seq模型。不依赖于外部模块和流水线集成,实现在一个统一模型中的语音翻译。


**Whisper输入的数据格式**
根据OpenAI公开的信息,Whisper可以支持多种语音输入格式,主要包括:

原始语音波形:比如单通道或者双通道的16kHz 16-bit PCM格式语音,可以直接输入到Whisper中。
语音特征:比如Mel频谱图(Mel spectrogram)或者MFCC特征等。这些是事先从语音波形中提取出来的二维特征表示。
嵌入向量:如果输入pipiline中有独立的语音编码/表征模块,可以将其输出的语音embedding向量直接输入到Whisper。
此外,对于音频编码,Whisper也可兼容多种格式:

无损编码:FLAC, WAV等
有损编码:Opus, MP3, AAC等
Whisper的输入各模块会包含相应解码器,转换成模型可接受的原始波形或特征表示进行处理。

所以简而言之,Whisper可以高度兼容各类语音输入,包含原始波形,特征提取,以及嵌入向量表示。这为其与多样的数据前处理流水线进行集成提供了灵活性。最终语音数据会转换为模型可直接处理的表示。

**Log-Mel Spectrogram 这是一种什么数据类型？**
Log-Mel Spectrogram 是一种常用的语音表征形式。它是将语音信号的 Mel Spectrogram 取对数后的结果。

Mel Spectrogram 是一种时频表示方法,它通过 Mel 标度在频率轴上进行非线性缩放,使低频部分扩展,高频部分压缩,更接近人耳的感知机制。

将 Mel Spectrogram 再取对数,就是 Log-Mel Spectrogram。取对数的目的是为了降低频谱动态范围,使频谱各部分信息得以更均衡的反映。

所以简单来说,Log-Mel Spectrogram 是一种经Mel标度和取对数预处理的语音时频表示,它保留了语音重要的特征信息,且动态范围压缩,利于 neural network 的训练。在语音识别、声纹识别等任务中被广泛使用作为输入特征表示。属于一种数字信号处理后的语音特征数据。


**Log-Mel Spectrogram数据为什么是二维的？**
Log-Mel Spectrogram把语音信号的时域和频域信息映射到一个二维矩阵上,这样它就同时表示了语音的动态变化特征。这就是为什么它是二维数据的原因:

其中一个维度(横轴)表示时间。语音信号随时间改变,所以取不同时间的切片,表示语音在时间上的动态演变。
另一个维度(纵轴)表示语音频谱。通过傅立叶变换得到语音短时段内的频率成分,反映语音谱信息。
矩阵中的每个像素点的值,表示该时间和频点上语音信号的能量大小。
所以通过二维矩阵,同时表示了语音在“时间+频率”上信号变化的能量分布,形成语音的时频图谱。
这样的二维表示,既有时间轴信息,又有频谱信息,比一维信号表示更能反映语音的动态特征。也更利于视觉分析语音结构。

之所以取对数还压缩到Mel刻度上,是为了减少动态范围,突出显示语音信息集中区域,方便模型学习。

所以 Log-Mel Spectrogram 把语音信号表示成了一个信息丰富、便于分析的二维时频图谱。这就是它为什么是一个二维的数据表示的原因。


**什么是语音特征？**
语音特征(Speech Features)是从原始的语音信号中提取出来的一些反映语音特性的特征参数。常用的语音特征主要有以下两类:

时域特征:反映语音波形本身在时间轴上的振幅变化特徵,比如短时能量、过零率、声音幅度的包络曲线等。
频域特征:通过对语音信号做傅里叶变换,转换到频域,得到的语音频谱信息,反映不同频带能量特征。常用的有滤波组功率、Mel频率倒谱系数(MFCC)、线性预测倒谱(LPCC)等。
提取这些语音特征的目的是为了表示出语音中包含的语音信息,便于建模分析,比直接使用语音波形更有利于训练算法模型。这些语音特征highlight了重要的语音属性,同时也实现了一定的归一化标准化。

所以简单来说,语音特征是从原始语音信号中抽取出的一些能够代表语音特性的特征参数,对语音进行编码的数字表达,以方便后续的计算机处理和模型分析。语音特征提取是语音分析处理流程的关键一步。