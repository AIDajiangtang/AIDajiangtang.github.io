---
published: false
layout: post
title: "预告"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "预告"
---


丢弃法



动机




不管加入多少噪音，图片中的内容始终都是能够看清除的
正则项的作用就是使得权重不要过大，避免过拟合
在数据中加入噪音等价于一个正则
丢弃法是在层之间加入噪音，丢弃法其实是一个正则








无偏差的加入噪音






假设x是上一层到下一层的输出
对x加入噪音，但是不要改变它的期望
丢弃法：对于x’，给定一个概率p，在p的概率中将真是的原始的输入变成0，在其它的地方除以一个（1-p），即将该输入变大。在一部份地方以一定的概率p变成0，在另外一部分地方以一定的概率变大，所以它的期望是不变的








使用丢弃法






h是第一个隐藏层的输出
dropout表示对h使用丢弃法








推理中的丢弃法




在预测的过程中因为不训练，所以不使用dropout
正则项只在训练中使用，它只会对权重产生影响，在预测的时候，权重不需要发生变化的情况下，不需要正则，所以在推理中不需要正则，确保在推理过程中能够有一个确定性的输出








总结




常用在多层感知机的隐藏层输出上，就是对应的全连接层的额隐藏层输出上，很少会用在CNN这类的模型上面








----to be continued---- 作者：如果我是泡橘子 https://www.bilibili.com/read/cv14317216/?from=readlist&jump_opus=1 出处：bilibili