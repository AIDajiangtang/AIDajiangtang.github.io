---
published: false
layout: post
title: "生成式AI"
categories: 我的AI新书
date: 2023-09-21 00:00:00 +0800
excerpt: "生成式AI"
---


**生成式AI的分类**
Large Language Models (LLMs) can have multiple categorizations based on their architecture, training data, and use case. 

Depending on if you aim to use the models for text, audio, video, image generation and so on, you might opt for a different type of model.

- Audio and speech recognition. For this purpose, Whisper-type models are a great choice as they're general-purpose and aimed at speech recognition. It's trained on diverse audio and can perform multilingual speech recognition. Learn more about Whisper type models here.

- Image generation. For image generation, DALL-E and Midjourney are two very known choices. DALL-E is offered by Azure OpenAI. Read more about DALL-E here and also in Chapter 9 of this curriculum.

- Text generation. Most models are trained on text generation and you have a large variety of choices from GPT-3.5 to GPT-4. They come at different costs with GPT-4 being the most expensive. It's worth looking into the Azure Open AI playground to evaluate which models best fit your needs in terms of capability and cost.

**Foundation Models versus LLMs**
The term Foundation Model was coined by Stanford researchers and defined as an AI model that follows some criteria, such as:

- They are trained using unsupervised learning or self-supervised learning, meaning they are trained on unlabeled multi-modal data, and they do not require human annotation or labeling of data for their training process.
- They are very large models, based on very deep neural networks trained on billions of parameters.
- They are normally intended to serve as a ‘foundation’ for other models, meaning they can be used as a starting point for other models to be built on top of, which can be done by fine-tuning.

To further clarify this distinction, let’s take ChatGPT as an example. To build the first version of ChatGPT, a model called GPT-3.5 served as the foundation model. This means that OpenAI used some chat-specific data to create a tuned version of GPT-3.5 that was specialized in performing well in conversational scenarios, such as chatbots.


**Open Source versus Proprietary Models**


**Embedding versus Image generation versus Text and Code generation**

**Service versus Model**




**Improving LLM results**
