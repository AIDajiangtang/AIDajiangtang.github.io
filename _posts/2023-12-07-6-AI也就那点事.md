---
published: false
layout: post
title: "一起学AI 6-AI也就那点事"
categories: 一起学AI

banner:
  video: https://vjs.zencdn.net/v/oceans.mp4
  loop: true
  volume: 0.1
  start_at: 8.5
  image: https://bit.ly/3xTmdUP
  opacity: 0.618
  background: "#000"
  height: "100vh"
  min_height: "38vh"
  heading_style: "font-size: 4.25em; font-weight: bold; text-decoration: underline"
  subheading_style: "color: gold"
excerpt: "一起学AI 6-AI也就那点事"
top: 7
---

A computer program is said to learn from experience E with respect to some class of tasks T,
and performance measure P, if its performance at tasks in T, as measured by P, improves with
experience E

前面我们介绍了如何获取数据，E主要来自于数据，虽然数据获取只是第一步，要输入到模型中还要经过一些预处理，今天主要介绍T。


前一篇文章，我们已经得到了表格，文本，图像，声音数据，接下来，就可以继续进行后续任务了。

![alt]({{ "assets/images/new book/6/ModelArch.png" | relative_url }})

但这节我们先不讨论模型的细节，权当它是一个无所不能的魔法黑盒。

## 表格

![alt]({{ "assets/images/new book/6/houseprice.png" | relative_url }})
在没有机器学习之前，如果让你预测房价，你可以直接计算所有房屋价格的均值和标准差，例如，均值为5000，标准差为20，对于任何一个新的房子，都可以给出一个很粗暴的预测：新房子价格为5000，上下不差20。

但如果数据中有一个湾区的豪宅，有这个异类的存在，用均值和方差来预测新房价就不合适了。

在机器学习中，像预测房价这种需要模型将输入特征向量映射成一个实数值的任务，统称为回归，线性回归模型来完成上述任务。


![alt]({{ "assets/images/new book/6/housepricepri.png" | relative_url }})
上述只考虑了面积一个特征，如果考虑了面积和楼层两个特征，模型会变成这样：
y=w0+w1*x1+w2*x2

但上述模型，无论选择多少个特征，它都是条直线，或者一个超平面，很难拟合复杂的数据。
所以，人们又发明了多项式回归模型，将特征的幂次作为特征，例如，面积的平方：
y=w0+w1*x1+w2*x2+w3*x1^2+w4*x2^2

![alt]({{ "assets/images/new book/6/Polynomial.png" | relative_url }})

可是选择几次呢？这需要人的经验做出判断。

神经网络的出现，解决了这个问题，它可以根据数据的变化，自动调整特征的幂次，从而拟合出一条曲线。

根据万能逼近定理，仅有一层隐藏层的神经网络就可以拟合任何函数。

![alt]({{ "assets/images/new book/6/ANN regission.png" | relative_url }})


在机器学习中除了线性回归，决策树回归，随机森林回归，LASSO回归，Ridge回归，XGBoost 回归同样能完成回归任务。


如果给你一张泰坦尼克号遇难者详细信息列表，你能用它来预测生存率。像这种模型将输入特征映射成一个概率值，称为二分类。

![alt]({{ "assets/images/new book/6/titanic.png" | relative_url }})

在机器学习中，通常用逻辑回归来完成二分类任务。
![alt]({{ "assets/images/new book/6/logistregission.png" | relative_url }})

模型输出值大于0.5就可以被判为正类。

在机器学习中，贝叶斯，决策树，随机森林，SVM，GBDT，XGBoost，LightGBM，CatBoost，这些模型，都可以用来完成二分类任务。

当然，与线性回归一样，对于决策面的选择，仍然需要经验。

同样，我们可以用神经网络来完成分类问题。
![alt]({{ "assets/images/new book/6/annclassiation.png" | relative_url }})

在神经网络中，对于多类别，可以通过模型输出多个概率值就能解决。
但如果用机器学习，朴素贝叶斯，决策树，随机森林可以处理多个类别输出，如果使用逻辑回归则需要构造多个二分类器实现多分类任务。

![alt]({{ "assets/images/new book/6/dctree.png" | relative_url }})
上面的决策树，叶子节点中，每一种颜色代表一个类别。


除了分类和回归，还有聚类，可以看作是特殊的分类，而是根据相似性，将数据分为不同的簇。

![alt]({{ "assets/images/new book/6/k-means-copy.jpg" | relative_url }})

但与前面提到的模型有所不同的是，它属于无监督学习，也就是不需要标签。
![alt]({{ "assets/images/new book/6/ml.png" | relative_url }})

深度学习作为机器学习的一个分支，同样分为了监督学习和无监督学习。



## 图像
图像分类

图像分类任务就是识别图像中物体类别，也就是模型将输入的图像映射到预定义的类别。同样分为二分类和多分类。

另外，在图像领域，还有多标签，也就是一幅图像中包含多个物体。

图像分类任务可并不是随着机器学习的发展才出现的。所以就会有传统方法和深度学习方法。

传统方法就是先使用人工设置的特征提取算子提取图像特征，例如SIFT，SURF，HOG等，这些特征类似前面提到的表格数据，然后将这些特征输入到分类器中。例如，支持向量机。

![alt]({{ "assets/images/new book/6/traditional classifation.png" | relative_url }})

但如何提取优质特征仍然离不开人的经验，深度学习方法，就是直接将图像输入到神经网络中，让神经网络自己学习特征。提取完特征就和表格数据处理一样，通过全连接层实现分类，回归。

这要感谢一种网络架构CNN，也就是卷积神经网络。
![alt]({{ "assets/images/new book/6/remotesensing-10-01229-ag.png" | relative_url }})

![alt]({{ "assets/images/new book/6/1680532048475.jpg" | relative_url }})


目标检测
目标检测不仅要识别图像中的物体类别，还要计算出物体所在的位置和边界框大小。

![alt]({{ "assets/images/new book/6/object detection.jpg" | relative_url }})

同样，目标检测的历史也很悠久。

![alt]({{ "assets/images/new book/6/sliding window.png" | relative_url }})

在卷积神经网络CNN出现以前，一般通过手工设计的特征和分类器来实现目标检测，首先从图像中选择候选区域，如滑动窗口或者选择性搜索，对每个候选区域进行特征提取，如Haar特征，HOG特征，SIFT特征等，最后对每个候选区域进行分类，如SVM，Adaboost。

CNN已经能提取特征，在前面图像分类中利用特征进行分类，这些提取特征的网络被称为骨干网络，目标检测的任务，就是在对这些特征进行分类的同时，计算出物体的位置和边界框大小。也就是回归。

这就形成了针对目标检测的网络结构，目前有两个主流，一个是一阶段目标检测，另一个是二阶段目标检测，两者各有千秋。

YOLO系列

Master系列



图像分割

图像分割就是对图像中每个像素进行分类，根据目标类别分为二分类，也就是目标和背景，以及多分类。

图像分割又分为实例分割和语义分割。

![alt]({{ "assets/images/new book/6/seg.png" | relative_url }})

传统图像分割方法包括，基于阈值：OSTU，基于边缘，基于区域：分水岭，基于图：图割。


深度学习中，全卷积网络实现图像分割，与前面输出类别，位置，大小不同，FCN输出和输入图像同样大小的分割结果，分割结果中每个像素点的值就是对应目标类别的索引。

![alt]({{ "assets/images/new book/6/fcn.png" | relative_url }})


FCN能输出和输入一样大小的分割结果，那同样能输出一张图像，这就是图像生成。

生成式AI。

早期的GAN，输入一个随机噪声，输出一张图像。
![alt]({{ "assets/images/new book/6/GAN.png" | relative_url }})

也可以输入一幅图像，然后输出变换风格后的图像StyleGAN。

也可以是一段描述性的文本，输出图像，因为涉及到文本和图像，这就是多模态。

## 视频
由连续的多帧构成了视频。

视频分类

姿态识别



## 文本

可以从图像中提取文字，OCR，也可以从语音中提取文字，语音识别。

### 文档检索
文档检索是一种从大量文档中找出与用户查询相关的文档的过程和技术。

文档检索的应用场景很广泛，例如网络搜索、文献检索、法律检索、专利检索等。

线性代数在自然语言处理中的应用

- 索引：将文档转换为文档特征向量。
- 查询：将查询转换为查询特征向量。
- 匹配：计算文档特征向量和查询特征向量之间的相似度。
- 反馈：返回Top k条结果。

使用词袋或者TF-IDF方法创建文档特征向量和查询特征向量，使用余弦夹角计算相似度。


概率统计在自然语言处理中的应用

语言模型

语言模型是一种用来描述语言中词序列出现概率的数学模型。它可以用来预测一个句子或一段文本在语言中的合理性，或者根据上下文预测下一个词的可能性。
语言模型经常使用在许多自然语言处理方面的应用，如语音识别[4]，机器翻译[5]，词性标注，句法分析[6]，手写体识别[7]和资讯检索。

![alt]({{ "assets/images/new book/6/lanmodel.png" | relative_url }})
上面的概率不好计算，马尔可夫性。

传统方法是构建语言概率模型，如N-gram模型，HMM模型，CRF模型，基于统计的方法。

![alt]({{ "assets/images/new book/6/N-gram.png" | relative_url }})

上面的概率是通过语料库统计得到。

N-gram本质上学习简单的语言的语法和语义信息。

P(d∣q)其中 q 表示一个查询，d 表示一篇文档。P(d∣q) 表示用户输入查询 q 的情况下，文档 d 出现的概率是多少？如果这个概率越高，我们就认为 q 和 d 之间的相关性越高。

利用贝叶斯定理，我们可以将 P(d∣q) 重写如下：
![alt]({{ "assets/images/new book/6/bayes.png" | relative_url }})


### 文本分类
判断一段文本是positive还是negative。判断新闻是属于经济，政治，体育。都是文本分类。

传统方法实现文本分类的一般步骤是：

文本预处理：Tokenlize。
特征提取：根据文本的内容或主题，选择合适的特征表示方法，如词袋模型、TF-IDF、N-Gram等，将文本转化为向量空间模型。
分类器选取：根据文本的类别和特征，选择合适的分类算法，如支持向量机、朴素贝叶斯、决策树、K近邻等，训练分类模型并进行预测。

深度学习模型架构，一般分为三种。
多对一
RNN最后一个输出包含了前面所有信息，可以用来作为分类。

多对多
Encode-Decoder模型。
机器翻译
ChatBot

单对多
给出关键词，输出相关文档。

### 机器翻译
机器翻译的前世今生

传统方法：
运动概率思维
第 1 步：将原始句子分成块
第 2 步：通过查字典方式为每个块找到所有可能的翻译
第 3 步：生成所有可能的句子并运动语言模型找到最有可能的句子

深度学习方法是利用神经网络，如RNN，LSTM，Transformer，BERT，GPT。
上述深度学习模型架构，划分为三种。
多对一
RNN最后一个输出包含了前面所有信息，可以用来作为分类。

多对多
sequence-to-sequence
Encoder-Decoder模型。
Encoder计算输入序列的特征表示，源语言的语义，语法，词义，这句话是什么意思。
Decoder根据Encoder提供的特征表示输出目标语言。

机器翻译
ChatBot

单对多
给出关键词，输出相关文档。

### 命名实体识别

实体识别是自然语言处理中的一项重要任务，指的是识别文本中具有特定意义的实体，例如人名、地名、组织名等。




N-gram虽然简单无法捕获长程依赖问题，无法完成复杂的NLP任务。



RNN
一个一个处理，无法并行处理，无法捕获长程依赖问题。

Transformer
自注意力机制。

互联网文本数据很多。
预训练模型
Bet，GPT

Bert：

GPT：
自回归语言模型
P r(It takes great courage to let yourself appear weak) =
P r(It) × P r(takes|It) × P r(great|It takes) × P r(courage|It takes great) ×
P r(to|It takes great courage) × P r(let|It takes great courage to) ×
P r(yourself|It takes great courage to let) ×
P r(appear|It takes great courage to let yourself) ×
P r(weak|It takes great courage to let yourself appear). 

基于预训练模型微调
fine-turning

prompting



### 文本生成
传统语言模型

GPT

### 文本总结

### 问答

Bert：
将问题和答案拼接在一起，让模型识别出Start，End

### 多模态

### 预训练模型：Bert，GPT


Bert使用Encoder架构，使用全部上下文，所以理解能力更强。
GPT使用Ddecoder架构，更容易生成文本。

RNN：Transformer
CBOW和skip-gram

## 声音
声音识别

翻译

传统方法和机器学习方法


最后，揭开模型的面纱。

前馈神经网络
输入特征向量，输出一个实数值，输出离散的概率值，对应了回归和分类。
卷积神经网络
输入二维矩阵，对应图像或者文本，输出特征图。分割结果，或者再经过前馈神经网络，回归活分类。
循环神经网络
多对一
多对多
一对多




使用 Encoder-decoder训练一个机器翻译模型，请详细叙述训练过程中如何使用标签，也就是目标语言